{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxomGSHH6Iquz7ahXsyRVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phantom1502/Deep-Learning/blob/main/Predict_Stock_Price_version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M3ThaZGvEaZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f3bba7-5f6a-4065-e12f-1857a08f6a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "#Config drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xauusd_df = pd.read_csv(\"./data/train_XAUUSD.csv\")\n",
        "xauusd_data = xauusd_df[xauusd_df.columns[0:12]].to_numpy()\n",
        "xauusd_label = xauusd_df[xauusd_df.columns[12:15]].to_numpy()\n",
        "\n",
        "eurusd_df = pd.read_csv(\"./data/train_EURUSD.csv\")\n",
        "eurusd_data = eurusd_df[eurusd_df.columns[0:12]].to_numpy()\n",
        "eurusd_label = eurusd_df[eurusd_df.columns[12:15]].to_numpy()\n",
        "\n",
        "gbpusd_df = pd.read_csv(\"./data/train_GBPUSD.csv\")\n",
        "gbpusd_data = gbpusd_df[gbpusd_df.columns[0:12]].to_numpy()\n",
        "gbpusd_label = gbpusd_df[gbpusd_df.columns[12:15]].to_numpy()\n",
        "\n",
        "raw_data = np.concatenate((xauusd_data, eurusd_data, gbpusd_data), axis=0)\n",
        "raw_label = np.concatenate((xauusd_label, eurusd_label, gbpusd_label), axis=0)\n",
        "\n",
        "#raw_data = xauusd_data\n",
        "#raw_label = xauusd_label"
      ],
      "metadata": {
        "id": "EqXIog0XhR0j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert__to_digital(data):\n",
        "    step = 16\n",
        "    ranges = []\n",
        "    distance = 2. / step\n",
        "    \n",
        "    result = np.zeros((len(data), 12 * (step + 1)))\n",
        "    for k,items in enumerate(data):\n",
        "        for i,item in enumerate(items):\n",
        "            for j in range(step + 1):\n",
        "                if item < (j - step/2) * distance + distance/2:\n",
        "                    result[k][i * 5 + j] = 1\n",
        "                    break\n",
        "    return result\n",
        "\n",
        "\n",
        "def normallize_price(data):\n",
        "    result = np.zeros((len(data), 12))\n",
        "    for i in range(len(data)):\n",
        "        # convert price to range [-1, 1]\n",
        "        min_price = min(data[i])\n",
        "        max_price = max(data[i])\n",
        "        result[i] = data[i] - (max_price + min_price)/2\n",
        "        result[i] = 2 * result[i]/(max_price - min_price)\n",
        "    return result\n",
        "\n",
        "norm_data = normallize_price(raw_data)\n",
        "data = convert__to_digital(norm_data)\n",
        "label =  np.asarray(raw_label).astype('float32')\n",
        "\n",
        "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.20, shuffle = False)\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)"
      ],
      "metadata": {
        "id": "aPk6aX8uh0ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111df054-bb10-4af6-9fbe-ececd6287a6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102794, 204)\n",
            "(25699, 204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normallize_price(data):\n",
        "    mean = data.mean(axis=1)\n",
        "    std = data\n",
        "    for i in range(len(data)):\n",
        "        mean = data[i].mean()\n",
        "        data[i] -= mean\n",
        "        std = data[i].std()\n",
        "        data[i] /= std\n",
        "    return data\n",
        "\n",
        "data = normallize_price(raw_data)\n",
        "label =  np.asarray(raw_label).astype('float32')\n",
        "\n",
        "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.20, shuffle = False)"
      ],
      "metadata": {
        "id": "3seC7p29HCQH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(data_train.shape[1],)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(data_train, label_train, epochs=400, batch_size=256, validation_data=[data_test, label_test])"
      ],
      "metadata": {
        "id": "iGiQUgyUkLWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bac55ec-6eb6-4009-89fa-bf3d7a1c2cf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.9783 - accuracy: 0.5009 - val_loss: 0.9672 - val_accuracy: 0.4953\n",
            "Epoch 2/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9612 - accuracy: 0.5015 - val_loss: 0.9662 - val_accuracy: 0.4883\n",
            "Epoch 3/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9579 - accuracy: 0.5014 - val_loss: 0.9643 - val_accuracy: 0.4928\n",
            "Epoch 4/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9555 - accuracy: 0.5019 - val_loss: 0.9642 - val_accuracy: 0.4952\n",
            "Epoch 5/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9538 - accuracy: 0.5021 - val_loss: 0.9690 - val_accuracy: 0.4910\n",
            "Epoch 6/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9512 - accuracy: 0.5023 - val_loss: 0.9692 - val_accuracy: 0.4868\n",
            "Epoch 7/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9492 - accuracy: 0.5037 - val_loss: 0.9686 - val_accuracy: 0.4943\n",
            "Epoch 8/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9466 - accuracy: 0.5039 - val_loss: 0.9695 - val_accuracy: 0.4846\n",
            "Epoch 9/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9440 - accuracy: 0.5053 - val_loss: 0.9743 - val_accuracy: 0.4855\n",
            "Epoch 10/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9413 - accuracy: 0.5065 - val_loss: 0.9774 - val_accuracy: 0.4868\n",
            "Epoch 11/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9388 - accuracy: 0.5094 - val_loss: 0.9864 - val_accuracy: 0.4785\n",
            "Epoch 12/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9360 - accuracy: 0.5100 - val_loss: 0.9860 - val_accuracy: 0.4879\n",
            "Epoch 13/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9336 - accuracy: 0.5129 - val_loss: 0.9813 - val_accuracy: 0.4689\n",
            "Epoch 14/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9305 - accuracy: 0.5139 - val_loss: 0.9874 - val_accuracy: 0.4785\n",
            "Epoch 15/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9283 - accuracy: 0.5169 - val_loss: 0.9917 - val_accuracy: 0.4718\n",
            "Epoch 16/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9255 - accuracy: 0.5188 - val_loss: 0.9914 - val_accuracy: 0.4750\n",
            "Epoch 17/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9231 - accuracy: 0.5222 - val_loss: 1.0011 - val_accuracy: 0.4772\n",
            "Epoch 18/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9204 - accuracy: 0.5239 - val_loss: 0.9984 - val_accuracy: 0.4710\n",
            "Epoch 19/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9179 - accuracy: 0.5239 - val_loss: 1.0146 - val_accuracy: 0.4848\n",
            "Epoch 20/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9151 - accuracy: 0.5259 - val_loss: 1.0017 - val_accuracy: 0.4704\n",
            "Epoch 21/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9132 - accuracy: 0.5295 - val_loss: 1.0028 - val_accuracy: 0.4591\n",
            "Epoch 22/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9104 - accuracy: 0.5298 - val_loss: 1.0090 - val_accuracy: 0.4678\n",
            "Epoch 23/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9080 - accuracy: 0.5336 - val_loss: 1.0131 - val_accuracy: 0.4594\n",
            "Epoch 24/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.5343 - val_loss: 1.0117 - val_accuracy: 0.4517\n",
            "Epoch 25/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9033 - accuracy: 0.5367 - val_loss: 1.0271 - val_accuracy: 0.4683\n",
            "Epoch 26/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9012 - accuracy: 0.5395 - val_loss: 1.0118 - val_accuracy: 0.4539\n",
            "Epoch 27/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8989 - accuracy: 0.5404 - val_loss: 1.0348 - val_accuracy: 0.4510\n",
            "Epoch 28/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8969 - accuracy: 0.5427 - val_loss: 1.0315 - val_accuracy: 0.4536\n",
            "Epoch 29/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8950 - accuracy: 0.5444 - val_loss: 1.0380 - val_accuracy: 0.4662\n",
            "Epoch 30/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8924 - accuracy: 0.5460 - val_loss: 1.0436 - val_accuracy: 0.4473\n",
            "Epoch 31/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8906 - accuracy: 0.5461 - val_loss: 1.0357 - val_accuracy: 0.4627\n",
            "Epoch 32/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8883 - accuracy: 0.5519 - val_loss: 1.0362 - val_accuracy: 0.4564\n",
            "Epoch 33/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8862 - accuracy: 0.5519 - val_loss: 1.0401 - val_accuracy: 0.4487\n",
            "Epoch 34/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8840 - accuracy: 0.5536 - val_loss: 1.0455 - val_accuracy: 0.4527\n",
            "Epoch 35/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8819 - accuracy: 0.5575 - val_loss: 1.0431 - val_accuracy: 0.4608\n",
            "Epoch 36/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8800 - accuracy: 0.5579 - val_loss: 1.0453 - val_accuracy: 0.4535\n",
            "Epoch 37/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8780 - accuracy: 0.5579 - val_loss: 1.0534 - val_accuracy: 0.4327\n",
            "Epoch 38/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8760 - accuracy: 0.5620 - val_loss: 1.0569 - val_accuracy: 0.4492\n",
            "Epoch 39/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.8743 - accuracy: 0.5646 - val_loss: 1.0592 - val_accuracy: 0.4425\n",
            "Epoch 40/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8727 - accuracy: 0.5642 - val_loss: 1.0575 - val_accuracy: 0.4499\n",
            "Epoch 41/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8706 - accuracy: 0.5677 - val_loss: 1.0796 - val_accuracy: 0.4381\n",
            "Epoch 42/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8686 - accuracy: 0.5682 - val_loss: 1.0705 - val_accuracy: 0.4573\n",
            "Epoch 43/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8667 - accuracy: 0.5697 - val_loss: 1.0686 - val_accuracy: 0.4546\n",
            "Epoch 44/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8647 - accuracy: 0.5709 - val_loss: 1.0731 - val_accuracy: 0.4425\n",
            "Epoch 45/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8628 - accuracy: 0.5725 - val_loss: 1.0856 - val_accuracy: 0.4546\n",
            "Epoch 46/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8613 - accuracy: 0.5747 - val_loss: 1.0787 - val_accuracy: 0.4365\n",
            "Epoch 47/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8593 - accuracy: 0.5753 - val_loss: 1.0770 - val_accuracy: 0.4368\n",
            "Epoch 48/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8574 - accuracy: 0.5782 - val_loss: 1.0742 - val_accuracy: 0.4525\n",
            "Epoch 49/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8558 - accuracy: 0.5778 - val_loss: 1.0919 - val_accuracy: 0.4446\n",
            "Epoch 50/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8542 - accuracy: 0.5801 - val_loss: 1.0925 - val_accuracy: 0.4489\n",
            "Epoch 51/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8528 - accuracy: 0.5797 - val_loss: 1.0863 - val_accuracy: 0.4474\n",
            "Epoch 52/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8513 - accuracy: 0.5815 - val_loss: 1.1036 - val_accuracy: 0.4460\n",
            "Epoch 53/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8489 - accuracy: 0.5840 - val_loss: 1.0938 - val_accuracy: 0.4420\n",
            "Epoch 54/400\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 0.8477 - accuracy: 0.5863 - val_loss: 1.1019 - val_accuracy: 0.4452\n",
            "Epoch 55/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.8466 - accuracy: 0.5867 - val_loss: 1.1015 - val_accuracy: 0.4388\n",
            "Epoch 56/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8450 - accuracy: 0.5872 - val_loss: 1.1338 - val_accuracy: 0.4568\n",
            "Epoch 57/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8433 - accuracy: 0.5876 - val_loss: 1.1126 - val_accuracy: 0.4458\n",
            "Epoch 58/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8419 - accuracy: 0.5894 - val_loss: 1.1211 - val_accuracy: 0.4389\n",
            "Epoch 59/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8406 - accuracy: 0.5909 - val_loss: 1.1168 - val_accuracy: 0.4449\n",
            "Epoch 60/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8392 - accuracy: 0.5908 - val_loss: 1.1112 - val_accuracy: 0.4373\n",
            "Epoch 61/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8375 - accuracy: 0.5943 - val_loss: 1.1262 - val_accuracy: 0.4299\n",
            "Epoch 62/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8365 - accuracy: 0.5932 - val_loss: 1.1201 - val_accuracy: 0.4519\n",
            "Epoch 63/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8349 - accuracy: 0.5939 - val_loss: 1.1234 - val_accuracy: 0.4391\n",
            "Epoch 64/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8335 - accuracy: 0.5960 - val_loss: 1.1341 - val_accuracy: 0.4455\n",
            "Epoch 65/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8321 - accuracy: 0.5954 - val_loss: 1.1281 - val_accuracy: 0.4438\n",
            "Epoch 66/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8307 - accuracy: 0.5969 - val_loss: 1.1385 - val_accuracy: 0.4327\n",
            "Epoch 67/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8297 - accuracy: 0.5990 - val_loss: 1.1402 - val_accuracy: 0.4353\n",
            "Epoch 68/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8287 - accuracy: 0.5997 - val_loss: 1.1286 - val_accuracy: 0.4450\n",
            "Epoch 69/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8277 - accuracy: 0.5994 - val_loss: 1.1429 - val_accuracy: 0.4326\n",
            "Epoch 70/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8258 - accuracy: 0.6012 - val_loss: 1.1650 - val_accuracy: 0.4320\n",
            "Epoch 71/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8248 - accuracy: 0.6025 - val_loss: 1.1350 - val_accuracy: 0.4397\n",
            "Epoch 72/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8235 - accuracy: 0.6030 - val_loss: 1.1456 - val_accuracy: 0.4439\n",
            "Epoch 73/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8229 - accuracy: 0.6026 - val_loss: 1.1529 - val_accuracy: 0.4503\n",
            "Epoch 74/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8213 - accuracy: 0.6053 - val_loss: 1.1570 - val_accuracy: 0.4369\n",
            "Epoch 75/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8193 - accuracy: 0.6055 - val_loss: 1.1621 - val_accuracy: 0.4308\n",
            "Epoch 76/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8186 - accuracy: 0.6067 - val_loss: 1.1641 - val_accuracy: 0.4479\n",
            "Epoch 77/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8179 - accuracy: 0.6064 - val_loss: 1.1541 - val_accuracy: 0.4413\n",
            "Epoch 78/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8157 - accuracy: 0.6071 - val_loss: 1.1686 - val_accuracy: 0.4343\n",
            "Epoch 79/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8151 - accuracy: 0.6075 - val_loss: 1.1443 - val_accuracy: 0.4432\n",
            "Epoch 80/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8143 - accuracy: 0.6101 - val_loss: 1.1419 - val_accuracy: 0.4408\n",
            "Epoch 81/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8138 - accuracy: 0.6093 - val_loss: 1.1664 - val_accuracy: 0.4331\n",
            "Epoch 82/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8126 - accuracy: 0.6108 - val_loss: 1.1720 - val_accuracy: 0.4354\n",
            "Epoch 83/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.8114 - accuracy: 0.6108 - val_loss: 1.1792 - val_accuracy: 0.4408\n",
            "Epoch 84/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8105 - accuracy: 0.6120 - val_loss: 1.1896 - val_accuracy: 0.4454\n",
            "Epoch 85/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8101 - accuracy: 0.6123 - val_loss: 1.1897 - val_accuracy: 0.4372\n",
            "Epoch 86/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8093 - accuracy: 0.6127 - val_loss: 1.1832 - val_accuracy: 0.4333\n",
            "Epoch 87/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8076 - accuracy: 0.6142 - val_loss: 1.1891 - val_accuracy: 0.4408\n",
            "Epoch 88/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8061 - accuracy: 0.6137 - val_loss: 1.1724 - val_accuracy: 0.4401\n",
            "Epoch 89/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8059 - accuracy: 0.6144 - val_loss: 1.1823 - val_accuracy: 0.4458\n",
            "Epoch 90/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8052 - accuracy: 0.6155 - val_loss: 1.2039 - val_accuracy: 0.4331\n",
            "Epoch 91/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8041 - accuracy: 0.6164 - val_loss: 1.1929 - val_accuracy: 0.4285\n",
            "Epoch 92/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8034 - accuracy: 0.6163 - val_loss: 1.2035 - val_accuracy: 0.4254\n",
            "Epoch 93/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8028 - accuracy: 0.6163 - val_loss: 1.1916 - val_accuracy: 0.4384\n",
            "Epoch 94/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8021 - accuracy: 0.6170 - val_loss: 1.2004 - val_accuracy: 0.4354\n",
            "Epoch 95/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8008 - accuracy: 0.6181 - val_loss: 1.2183 - val_accuracy: 0.4383\n",
            "Epoch 96/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7999 - accuracy: 0.6186 - val_loss: 1.2056 - val_accuracy: 0.4392\n",
            "Epoch 97/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7993 - accuracy: 0.6188 - val_loss: 1.1978 - val_accuracy: 0.4356\n",
            "Epoch 98/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7986 - accuracy: 0.6199 - val_loss: 1.1908 - val_accuracy: 0.4366\n",
            "Epoch 99/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7981 - accuracy: 0.6195 - val_loss: 1.2334 - val_accuracy: 0.4454\n",
            "Epoch 100/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7971 - accuracy: 0.6206 - val_loss: 1.1750 - val_accuracy: 0.4422\n",
            "Epoch 101/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7963 - accuracy: 0.6208 - val_loss: 1.2249 - val_accuracy: 0.4460\n",
            "Epoch 102/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7963 - accuracy: 0.6199 - val_loss: 1.2120 - val_accuracy: 0.4331\n",
            "Epoch 103/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7949 - accuracy: 0.6217 - val_loss: 1.2052 - val_accuracy: 0.4384\n",
            "Epoch 104/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7941 - accuracy: 0.6221 - val_loss: 1.2067 - val_accuracy: 0.4399\n",
            "Epoch 105/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7935 - accuracy: 0.6228 - val_loss: 1.2335 - val_accuracy: 0.4355\n",
            "Epoch 106/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.7923 - accuracy: 0.6227 - val_loss: 1.2353 - val_accuracy: 0.4513\n",
            "Epoch 107/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7925 - accuracy: 0.6248 - val_loss: 1.2173 - val_accuracy: 0.4326\n",
            "Epoch 108/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7907 - accuracy: 0.6252 - val_loss: 1.2283 - val_accuracy: 0.4414\n",
            "Epoch 109/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7906 - accuracy: 0.6256 - val_loss: 1.2484 - val_accuracy: 0.4352\n",
            "Epoch 110/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7892 - accuracy: 0.6267 - val_loss: 1.2239 - val_accuracy: 0.4376\n",
            "Epoch 111/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7898 - accuracy: 0.6252 - val_loss: 1.2407 - val_accuracy: 0.4351\n",
            "Epoch 112/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7883 - accuracy: 0.6253 - val_loss: 1.2289 - val_accuracy: 0.4424\n",
            "Epoch 113/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7878 - accuracy: 0.6279 - val_loss: 1.2390 - val_accuracy: 0.4414\n",
            "Epoch 114/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7873 - accuracy: 0.6270 - val_loss: 1.2384 - val_accuracy: 0.4438\n",
            "Epoch 115/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7864 - accuracy: 0.6273 - val_loss: 1.2407 - val_accuracy: 0.4411\n",
            "Epoch 116/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7848 - accuracy: 0.6301 - val_loss: 1.2463 - val_accuracy: 0.4340\n",
            "Epoch 117/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7851 - accuracy: 0.6297 - val_loss: 1.2325 - val_accuracy: 0.4399\n",
            "Epoch 118/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7850 - accuracy: 0.6272 - val_loss: 1.2409 - val_accuracy: 0.4285\n",
            "Epoch 119/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7837 - accuracy: 0.6302 - val_loss: 1.2550 - val_accuracy: 0.4367\n",
            "Epoch 120/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7838 - accuracy: 0.6282 - val_loss: 1.2465 - val_accuracy: 0.4392\n",
            "Epoch 121/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7834 - accuracy: 0.6297 - val_loss: 1.2725 - val_accuracy: 0.4380\n",
            "Epoch 122/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7828 - accuracy: 0.6287 - val_loss: 1.2465 - val_accuracy: 0.4404\n",
            "Epoch 123/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7814 - accuracy: 0.6304 - val_loss: 1.2651 - val_accuracy: 0.4313\n",
            "Epoch 124/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7807 - accuracy: 0.6309 - val_loss: 1.2577 - val_accuracy: 0.4300\n",
            "Epoch 125/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7804 - accuracy: 0.6307 - val_loss: 1.2694 - val_accuracy: 0.4402\n",
            "Epoch 126/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7799 - accuracy: 0.6314 - val_loss: 1.2642 - val_accuracy: 0.4357\n",
            "Epoch 127/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7800 - accuracy: 0.6316 - val_loss: 1.2692 - val_accuracy: 0.4286\n",
            "Epoch 128/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7792 - accuracy: 0.6311 - val_loss: 1.2630 - val_accuracy: 0.4356\n",
            "Epoch 129/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7784 - accuracy: 0.6327 - val_loss: 1.2557 - val_accuracy: 0.4329\n",
            "Epoch 130/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7788 - accuracy: 0.6311 - val_loss: 1.2486 - val_accuracy: 0.4349\n",
            "Epoch 131/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7777 - accuracy: 0.6330 - val_loss: 1.2699 - val_accuracy: 0.4442\n",
            "Epoch 132/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7774 - accuracy: 0.6329 - val_loss: 1.2613 - val_accuracy: 0.4296\n",
            "Epoch 133/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7772 - accuracy: 0.6325 - val_loss: 1.2764 - val_accuracy: 0.4286\n",
            "Epoch 134/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7757 - accuracy: 0.6325 - val_loss: 1.2763 - val_accuracy: 0.4427\n",
            "Epoch 135/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7757 - accuracy: 0.6329 - val_loss: 1.2821 - val_accuracy: 0.4378\n",
            "Epoch 136/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7753 - accuracy: 0.6337 - val_loss: 1.2867 - val_accuracy: 0.4303\n",
            "Epoch 137/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7751 - accuracy: 0.6336 - val_loss: 1.2984 - val_accuracy: 0.4333\n",
            "Epoch 138/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7744 - accuracy: 0.6340 - val_loss: 1.2845 - val_accuracy: 0.4362\n",
            "Epoch 139/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7735 - accuracy: 0.6337 - val_loss: 1.2714 - val_accuracy: 0.4467\n",
            "Epoch 140/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7732 - accuracy: 0.6350 - val_loss: 1.2886 - val_accuracy: 0.4331\n",
            "Epoch 141/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7733 - accuracy: 0.6344 - val_loss: 1.2659 - val_accuracy: 0.4372\n",
            "Epoch 142/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7728 - accuracy: 0.6344 - val_loss: 1.2941 - val_accuracy: 0.4396\n",
            "Epoch 143/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7734 - accuracy: 0.6359 - val_loss: 1.2723 - val_accuracy: 0.4311\n",
            "Epoch 144/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7713 - accuracy: 0.6355 - val_loss: 1.2826 - val_accuracy: 0.4304\n",
            "Epoch 145/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7714 - accuracy: 0.6368 - val_loss: 1.2943 - val_accuracy: 0.4338\n",
            "Epoch 146/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7707 - accuracy: 0.6368 - val_loss: 1.2986 - val_accuracy: 0.4365\n",
            "Epoch 147/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7701 - accuracy: 0.6376 - val_loss: 1.2883 - val_accuracy: 0.4367\n",
            "Epoch 148/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7696 - accuracy: 0.6366 - val_loss: 1.2897 - val_accuracy: 0.4281\n",
            "Epoch 149/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7697 - accuracy: 0.6376 - val_loss: 1.2998 - val_accuracy: 0.4346\n",
            "Epoch 150/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7689 - accuracy: 0.6371 - val_loss: 1.2990 - val_accuracy: 0.4320\n",
            "Epoch 151/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7685 - accuracy: 0.6382 - val_loss: 1.3106 - val_accuracy: 0.4357\n",
            "Epoch 152/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.7675 - accuracy: 0.6396 - val_loss: 1.2961 - val_accuracy: 0.4392\n",
            "Epoch 153/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7669 - accuracy: 0.6385 - val_loss: 1.3227 - val_accuracy: 0.4369\n",
            "Epoch 154/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7671 - accuracy: 0.6390 - val_loss: 1.3084 - val_accuracy: 0.4368\n",
            "Epoch 155/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7674 - accuracy: 0.6391 - val_loss: 1.3153 - val_accuracy: 0.4398\n",
            "Epoch 156/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7657 - accuracy: 0.6388 - val_loss: 1.2962 - val_accuracy: 0.4345\n",
            "Epoch 157/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7662 - accuracy: 0.6414 - val_loss: 1.2858 - val_accuracy: 0.4366\n",
            "Epoch 158/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7664 - accuracy: 0.6383 - val_loss: 1.3052 - val_accuracy: 0.4285\n",
            "Epoch 159/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.7656 - accuracy: 0.6399 - val_loss: 1.3163 - val_accuracy: 0.4381\n",
            "Epoch 160/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7647 - accuracy: 0.6397 - val_loss: 1.3215 - val_accuracy: 0.4325\n",
            "Epoch 161/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7640 - accuracy: 0.6408 - val_loss: 1.2974 - val_accuracy: 0.4326\n",
            "Epoch 162/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7641 - accuracy: 0.6400 - val_loss: 1.3261 - val_accuracy: 0.4333\n",
            "Epoch 163/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7641 - accuracy: 0.6408 - val_loss: 1.3201 - val_accuracy: 0.4225\n",
            "Epoch 164/400\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.7635 - accuracy: 0.6413 - val_loss: 1.3108 - val_accuracy: 0.4390\n",
            "Epoch 165/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7628 - accuracy: 0.6412 - val_loss: 1.3241 - val_accuracy: 0.4454\n",
            "Epoch 166/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7629 - accuracy: 0.6409 - val_loss: 1.3143 - val_accuracy: 0.4408\n",
            "Epoch 167/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7619 - accuracy: 0.6422 - val_loss: 1.3172 - val_accuracy: 0.4390\n",
            "Epoch 168/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7613 - accuracy: 0.6421 - val_loss: 1.3206 - val_accuracy: 0.4349\n",
            "Epoch 169/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7616 - accuracy: 0.6421 - val_loss: 1.3358 - val_accuracy: 0.4363\n",
            "Epoch 170/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7622 - accuracy: 0.6422 - val_loss: 1.3223 - val_accuracy: 0.4359\n",
            "Epoch 171/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7610 - accuracy: 0.6418 - val_loss: 1.3486 - val_accuracy: 0.4287\n",
            "Epoch 172/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7604 - accuracy: 0.6423 - val_loss: 1.3105 - val_accuracy: 0.4327\n",
            "Epoch 173/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7605 - accuracy: 0.6433 - val_loss: 1.3157 - val_accuracy: 0.4390\n",
            "Epoch 174/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7599 - accuracy: 0.6421 - val_loss: 1.2922 - val_accuracy: 0.4335\n",
            "Epoch 175/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7591 - accuracy: 0.6443 - val_loss: 1.3122 - val_accuracy: 0.4313\n",
            "Epoch 176/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7599 - accuracy: 0.6439 - val_loss: 1.3243 - val_accuracy: 0.4283\n",
            "Epoch 177/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7593 - accuracy: 0.6443 - val_loss: 1.3203 - val_accuracy: 0.4350\n",
            "Epoch 178/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7592 - accuracy: 0.6426 - val_loss: 1.3318 - val_accuracy: 0.4315\n",
            "Epoch 179/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7580 - accuracy: 0.6435 - val_loss: 1.3570 - val_accuracy: 0.4337\n",
            "Epoch 180/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7583 - accuracy: 0.6439 - val_loss: 1.3387 - val_accuracy: 0.4305\n",
            "Epoch 181/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7577 - accuracy: 0.6458 - val_loss: 1.3318 - val_accuracy: 0.4334\n",
            "Epoch 182/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7578 - accuracy: 0.6432 - val_loss: 1.3514 - val_accuracy: 0.4364\n",
            "Epoch 183/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7567 - accuracy: 0.6460 - val_loss: 1.3156 - val_accuracy: 0.4394\n",
            "Epoch 184/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7569 - accuracy: 0.6456 - val_loss: 1.3358 - val_accuracy: 0.4287\n",
            "Epoch 185/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7568 - accuracy: 0.6447 - val_loss: 1.3379 - val_accuracy: 0.4346\n",
            "Epoch 186/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7560 - accuracy: 0.6460 - val_loss: 1.3355 - val_accuracy: 0.4295\n",
            "Epoch 187/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7563 - accuracy: 0.6459 - val_loss: 1.3583 - val_accuracy: 0.4412\n",
            "Epoch 188/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7556 - accuracy: 0.6460 - val_loss: 1.3312 - val_accuracy: 0.4348\n",
            "Epoch 189/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7559 - accuracy: 0.6462 - val_loss: 1.3391 - val_accuracy: 0.4354\n",
            "Epoch 190/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7552 - accuracy: 0.6466 - val_loss: 1.3495 - val_accuracy: 0.4343\n",
            "Epoch 191/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7549 - accuracy: 0.6462 - val_loss: 1.3608 - val_accuracy: 0.4363\n",
            "Epoch 192/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7543 - accuracy: 0.6460 - val_loss: 1.3580 - val_accuracy: 0.4333\n",
            "Epoch 193/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7543 - accuracy: 0.6457 - val_loss: 1.3513 - val_accuracy: 0.4285\n",
            "Epoch 194/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7537 - accuracy: 0.6458 - val_loss: 1.3399 - val_accuracy: 0.4331\n",
            "Epoch 195/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7531 - accuracy: 0.6475 - val_loss: 1.3516 - val_accuracy: 0.4441\n",
            "Epoch 196/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7536 - accuracy: 0.6478 - val_loss: 1.3372 - val_accuracy: 0.4431\n",
            "Epoch 197/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7532 - accuracy: 0.6475 - val_loss: 1.3582 - val_accuracy: 0.4287\n",
            "Epoch 198/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7526 - accuracy: 0.6465 - val_loss: 1.3585 - val_accuracy: 0.4289\n",
            "Epoch 199/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7527 - accuracy: 0.6469 - val_loss: 1.3617 - val_accuracy: 0.4311\n",
            "Epoch 200/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7524 - accuracy: 0.6481 - val_loss: 1.3400 - val_accuracy: 0.4330\n",
            "Epoch 201/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7515 - accuracy: 0.6482 - val_loss: 1.3670 - val_accuracy: 0.4345\n",
            "Epoch 202/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7515 - accuracy: 0.6499 - val_loss: 1.3658 - val_accuracy: 0.4291\n",
            "Epoch 203/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7509 - accuracy: 0.6492 - val_loss: 1.3438 - val_accuracy: 0.4339\n",
            "Epoch 204/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7514 - accuracy: 0.6490 - val_loss: 1.3427 - val_accuracy: 0.4364\n",
            "Epoch 205/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7511 - accuracy: 0.6486 - val_loss: 1.3739 - val_accuracy: 0.4311\n",
            "Epoch 206/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7510 - accuracy: 0.6485 - val_loss: 1.3730 - val_accuracy: 0.4383\n",
            "Epoch 207/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7507 - accuracy: 0.6498 - val_loss: 1.3661 - val_accuracy: 0.4290\n",
            "Epoch 208/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7501 - accuracy: 0.6487 - val_loss: 1.3433 - val_accuracy: 0.4419\n",
            "Epoch 209/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7496 - accuracy: 0.6493 - val_loss: 1.3529 - val_accuracy: 0.4331\n",
            "Epoch 210/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7497 - accuracy: 0.6504 - val_loss: 1.4023 - val_accuracy: 0.4319\n",
            "Epoch 211/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7491 - accuracy: 0.6494 - val_loss: 1.3701 - val_accuracy: 0.4303\n",
            "Epoch 212/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7489 - accuracy: 0.6508 - val_loss: 1.3429 - val_accuracy: 0.4250\n",
            "Epoch 213/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7495 - accuracy: 0.6495 - val_loss: 1.3600 - val_accuracy: 0.4432\n",
            "Epoch 214/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7487 - accuracy: 0.6500 - val_loss: 1.3856 - val_accuracy: 0.4365\n",
            "Epoch 215/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7478 - accuracy: 0.6506 - val_loss: 1.3992 - val_accuracy: 0.4373\n",
            "Epoch 216/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7479 - accuracy: 0.6513 - val_loss: 1.3941 - val_accuracy: 0.4295\n",
            "Epoch 217/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7478 - accuracy: 0.6509 - val_loss: 1.3674 - val_accuracy: 0.4292\n",
            "Epoch 218/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7476 - accuracy: 0.6506 - val_loss: 1.3565 - val_accuracy: 0.4334\n",
            "Epoch 219/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7466 - accuracy: 0.6505 - val_loss: 1.3999 - val_accuracy: 0.4345\n",
            "Epoch 220/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7477 - accuracy: 0.6501 - val_loss: 1.3645 - val_accuracy: 0.4323\n",
            "Epoch 221/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7461 - accuracy: 0.6510 - val_loss: 1.3925 - val_accuracy: 0.4347\n",
            "Epoch 222/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7468 - accuracy: 0.6516 - val_loss: 1.3928 - val_accuracy: 0.4319\n",
            "Epoch 223/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7457 - accuracy: 0.6512 - val_loss: 1.3701 - val_accuracy: 0.4314\n",
            "Epoch 224/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7459 - accuracy: 0.6511 - val_loss: 1.3751 - val_accuracy: 0.4239\n",
            "Epoch 225/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7463 - accuracy: 0.6507 - val_loss: 1.3852 - val_accuracy: 0.4311\n",
            "Epoch 226/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7466 - accuracy: 0.6512 - val_loss: 1.3679 - val_accuracy: 0.4381\n",
            "Epoch 227/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7457 - accuracy: 0.6510 - val_loss: 1.3801 - val_accuracy: 0.4376\n",
            "Epoch 228/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7451 - accuracy: 0.6530 - val_loss: 1.3812 - val_accuracy: 0.4354\n",
            "Epoch 229/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7441 - accuracy: 0.6528 - val_loss: 1.3934 - val_accuracy: 0.4337\n",
            "Epoch 230/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7446 - accuracy: 0.6530 - val_loss: 1.4130 - val_accuracy: 0.4355\n",
            "Epoch 231/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7454 - accuracy: 0.6525 - val_loss: 1.3963 - val_accuracy: 0.4396\n",
            "Epoch 232/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7440 - accuracy: 0.6548 - val_loss: 1.3737 - val_accuracy: 0.4424\n",
            "Epoch 233/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7447 - accuracy: 0.6517 - val_loss: 1.3739 - val_accuracy: 0.4398\n",
            "Epoch 234/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7442 - accuracy: 0.6540 - val_loss: 1.3779 - val_accuracy: 0.4345\n",
            "Epoch 235/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7441 - accuracy: 0.6538 - val_loss: 1.3699 - val_accuracy: 0.4367\n",
            "Epoch 236/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7439 - accuracy: 0.6525 - val_loss: 1.3623 - val_accuracy: 0.4295\n",
            "Epoch 237/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7432 - accuracy: 0.6533 - val_loss: 1.3968 - val_accuracy: 0.4404\n",
            "Epoch 238/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7429 - accuracy: 0.6540 - val_loss: 1.4021 - val_accuracy: 0.4259\n",
            "Epoch 239/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7426 - accuracy: 0.6533 - val_loss: 1.3865 - val_accuracy: 0.4392\n",
            "Epoch 240/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7422 - accuracy: 0.6539 - val_loss: 1.3859 - val_accuracy: 0.4316\n",
            "Epoch 241/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7430 - accuracy: 0.6526 - val_loss: 1.3858 - val_accuracy: 0.4241\n",
            "Epoch 242/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7421 - accuracy: 0.6535 - val_loss: 1.3772 - val_accuracy: 0.4308\n",
            "Epoch 243/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7422 - accuracy: 0.6546 - val_loss: 1.3874 - val_accuracy: 0.4312\n",
            "Epoch 244/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7413 - accuracy: 0.6539 - val_loss: 1.3781 - val_accuracy: 0.4395\n",
            "Epoch 245/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7420 - accuracy: 0.6528 - val_loss: 1.3926 - val_accuracy: 0.4272\n",
            "Epoch 246/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7403 - accuracy: 0.6549 - val_loss: 1.4316 - val_accuracy: 0.4410\n",
            "Epoch 247/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7416 - accuracy: 0.6546 - val_loss: 1.4172 - val_accuracy: 0.4385\n",
            "Epoch 248/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7405 - accuracy: 0.6544 - val_loss: 1.4208 - val_accuracy: 0.4399\n",
            "Epoch 249/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7406 - accuracy: 0.6558 - val_loss: 1.4078 - val_accuracy: 0.4335\n",
            "Epoch 250/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7399 - accuracy: 0.6556 - val_loss: 1.3942 - val_accuracy: 0.4286\n",
            "Epoch 251/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7403 - accuracy: 0.6549 - val_loss: 1.4000 - val_accuracy: 0.4259\n",
            "Epoch 252/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7406 - accuracy: 0.6548 - val_loss: 1.3936 - val_accuracy: 0.4359\n",
            "Epoch 253/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7405 - accuracy: 0.6548 - val_loss: 1.3958 - val_accuracy: 0.4301\n",
            "Epoch 254/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7402 - accuracy: 0.6547 - val_loss: 1.3956 - val_accuracy: 0.4326\n",
            "Epoch 255/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7394 - accuracy: 0.6560 - val_loss: 1.4099 - val_accuracy: 0.4344\n",
            "Epoch 256/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7393 - accuracy: 0.6549 - val_loss: 1.3984 - val_accuracy: 0.4354\n",
            "Epoch 257/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7392 - accuracy: 0.6560 - val_loss: 1.3961 - val_accuracy: 0.4289\n",
            "Epoch 258/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7387 - accuracy: 0.6542 - val_loss: 1.4184 - val_accuracy: 0.4395\n",
            "Epoch 259/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7377 - accuracy: 0.6569 - val_loss: 1.4143 - val_accuracy: 0.4402\n",
            "Epoch 260/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7391 - accuracy: 0.6555 - val_loss: 1.3957 - val_accuracy: 0.4290\n",
            "Epoch 261/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7379 - accuracy: 0.6572 - val_loss: 1.4201 - val_accuracy: 0.4330\n",
            "Epoch 262/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7382 - accuracy: 0.6569 - val_loss: 1.4194 - val_accuracy: 0.4349\n",
            "Epoch 263/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7371 - accuracy: 0.6566 - val_loss: 1.4033 - val_accuracy: 0.4303\n",
            "Epoch 264/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7376 - accuracy: 0.6565 - val_loss: 1.4330 - val_accuracy: 0.4341\n",
            "Epoch 265/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7377 - accuracy: 0.6573 - val_loss: 1.3690 - val_accuracy: 0.4304\n",
            "Epoch 266/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7371 - accuracy: 0.6569 - val_loss: 1.4088 - val_accuracy: 0.4262\n",
            "Epoch 267/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7374 - accuracy: 0.6562 - val_loss: 1.4124 - val_accuracy: 0.4325\n",
            "Epoch 268/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7373 - accuracy: 0.6578 - val_loss: 1.4236 - val_accuracy: 0.4318\n",
            "Epoch 269/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7364 - accuracy: 0.6567 - val_loss: 1.4435 - val_accuracy: 0.4354\n",
            "Epoch 270/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7368 - accuracy: 0.6555 - val_loss: 1.4320 - val_accuracy: 0.4368\n",
            "Epoch 271/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7362 - accuracy: 0.6560 - val_loss: 1.3891 - val_accuracy: 0.4297\n",
            "Epoch 272/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7367 - accuracy: 0.6566 - val_loss: 1.4072 - val_accuracy: 0.4243\n",
            "Epoch 273/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7362 - accuracy: 0.6554 - val_loss: 1.4009 - val_accuracy: 0.4352\n",
            "Epoch 274/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7352 - accuracy: 0.6581 - val_loss: 1.4038 - val_accuracy: 0.4243\n",
            "Epoch 275/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7363 - accuracy: 0.6570 - val_loss: 1.4125 - val_accuracy: 0.4243\n",
            "Epoch 276/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7358 - accuracy: 0.6590 - val_loss: 1.4552 - val_accuracy: 0.4415\n",
            "Epoch 277/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7342 - accuracy: 0.6597 - val_loss: 1.4237 - val_accuracy: 0.4311\n",
            "Epoch 278/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7357 - accuracy: 0.6566 - val_loss: 1.4287 - val_accuracy: 0.4185\n",
            "Epoch 279/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7349 - accuracy: 0.6575 - val_loss: 1.4295 - val_accuracy: 0.4241\n",
            "Epoch 280/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7344 - accuracy: 0.6587 - val_loss: 1.4602 - val_accuracy: 0.4407\n",
            "Epoch 281/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7348 - accuracy: 0.6584 - val_loss: 1.3999 - val_accuracy: 0.4332\n",
            "Epoch 282/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7345 - accuracy: 0.6572 - val_loss: 1.4146 - val_accuracy: 0.4367\n",
            "Epoch 283/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7340 - accuracy: 0.6582 - val_loss: 1.4450 - val_accuracy: 0.4300\n",
            "Epoch 284/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7339 - accuracy: 0.6577 - val_loss: 1.4732 - val_accuracy: 0.4395\n",
            "Epoch 285/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7342 - accuracy: 0.6597 - val_loss: 1.4211 - val_accuracy: 0.4382\n",
            "Epoch 286/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7339 - accuracy: 0.6572 - val_loss: 1.4529 - val_accuracy: 0.4359\n",
            "Epoch 287/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7330 - accuracy: 0.6580 - val_loss: 1.4496 - val_accuracy: 0.4320\n",
            "Epoch 288/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7326 - accuracy: 0.6578 - val_loss: 1.3894 - val_accuracy: 0.4279\n",
            "Epoch 289/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7338 - accuracy: 0.6571 - val_loss: 1.4641 - val_accuracy: 0.4335\n",
            "Epoch 290/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7324 - accuracy: 0.6591 - val_loss: 1.4311 - val_accuracy: 0.4331\n",
            "Epoch 291/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7328 - accuracy: 0.6585 - val_loss: 1.4442 - val_accuracy: 0.4411\n",
            "Epoch 292/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7327 - accuracy: 0.6572 - val_loss: 1.4377 - val_accuracy: 0.4371\n",
            "Epoch 293/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7329 - accuracy: 0.6589 - val_loss: 1.4410 - val_accuracy: 0.4349\n",
            "Epoch 294/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7322 - accuracy: 0.6600 - val_loss: 1.4320 - val_accuracy: 0.4295\n",
            "Epoch 295/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7326 - accuracy: 0.6598 - val_loss: 1.4462 - val_accuracy: 0.4286\n",
            "Epoch 296/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7317 - accuracy: 0.6590 - val_loss: 1.4443 - val_accuracy: 0.4326\n",
            "Epoch 297/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7319 - accuracy: 0.6596 - val_loss: 1.4466 - val_accuracy: 0.4311\n",
            "Epoch 298/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7316 - accuracy: 0.6600 - val_loss: 1.4417 - val_accuracy: 0.4408\n",
            "Epoch 299/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7311 - accuracy: 0.6585 - val_loss: 1.4703 - val_accuracy: 0.4325\n",
            "Epoch 300/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7311 - accuracy: 0.6594 - val_loss: 1.4542 - val_accuracy: 0.4374\n",
            "Epoch 301/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7311 - accuracy: 0.6599 - val_loss: 1.4338 - val_accuracy: 0.4352\n",
            "Epoch 302/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7312 - accuracy: 0.6582 - val_loss: 1.4246 - val_accuracy: 0.4347\n",
            "Epoch 303/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7308 - accuracy: 0.6604 - val_loss: 1.4750 - val_accuracy: 0.4345\n",
            "Epoch 304/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7314 - accuracy: 0.6592 - val_loss: 1.4301 - val_accuracy: 0.4285\n",
            "Epoch 305/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7302 - accuracy: 0.6588 - val_loss: 1.4384 - val_accuracy: 0.4299\n",
            "Epoch 306/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7305 - accuracy: 0.6598 - val_loss: 1.4630 - val_accuracy: 0.4419\n",
            "Epoch 307/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7307 - accuracy: 0.6604 - val_loss: 1.4360 - val_accuracy: 0.4283\n",
            "Epoch 308/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7303 - accuracy: 0.6595 - val_loss: 1.4512 - val_accuracy: 0.4394\n",
            "Epoch 309/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7303 - accuracy: 0.6602 - val_loss: 1.4384 - val_accuracy: 0.4313\n",
            "Epoch 310/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7294 - accuracy: 0.6607 - val_loss: 1.4974 - val_accuracy: 0.4347\n",
            "Epoch 311/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7314 - accuracy: 0.6598 - val_loss: 1.4311 - val_accuracy: 0.4310\n",
            "Epoch 312/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7293 - accuracy: 0.6608 - val_loss: 1.4347 - val_accuracy: 0.4313\n",
            "Epoch 313/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7291 - accuracy: 0.6615 - val_loss: 1.4335 - val_accuracy: 0.4300\n",
            "Epoch 314/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7290 - accuracy: 0.6613 - val_loss: 1.4733 - val_accuracy: 0.4293\n",
            "Epoch 315/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7285 - accuracy: 0.6607 - val_loss: 1.4679 - val_accuracy: 0.4338\n",
            "Epoch 316/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7289 - accuracy: 0.6601 - val_loss: 1.4489 - val_accuracy: 0.4345\n",
            "Epoch 317/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7284 - accuracy: 0.6602 - val_loss: 1.4373 - val_accuracy: 0.4281\n",
            "Epoch 318/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7286 - accuracy: 0.6610 - val_loss: 1.4356 - val_accuracy: 0.4347\n",
            "Epoch 319/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7287 - accuracy: 0.6610 - val_loss: 1.4367 - val_accuracy: 0.4288\n",
            "Epoch 320/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7293 - accuracy: 0.6602 - val_loss: 1.4580 - val_accuracy: 0.4293\n",
            "Epoch 321/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7284 - accuracy: 0.6615 - val_loss: 1.4623 - val_accuracy: 0.4280\n",
            "Epoch 322/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7278 - accuracy: 0.6613 - val_loss: 1.4593 - val_accuracy: 0.4360\n",
            "Epoch 323/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7281 - accuracy: 0.6608 - val_loss: 1.4284 - val_accuracy: 0.4238\n",
            "Epoch 324/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7273 - accuracy: 0.6620 - val_loss: 1.4474 - val_accuracy: 0.4319\n",
            "Epoch 325/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7283 - accuracy: 0.6604 - val_loss: 1.4410 - val_accuracy: 0.4274\n",
            "Epoch 326/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7274 - accuracy: 0.6616 - val_loss: 1.4552 - val_accuracy: 0.4287\n",
            "Epoch 327/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7270 - accuracy: 0.6612 - val_loss: 1.4875 - val_accuracy: 0.4271\n",
            "Epoch 328/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7274 - accuracy: 0.6610 - val_loss: 1.4705 - val_accuracy: 0.4438\n",
            "Epoch 329/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7276 - accuracy: 0.6625 - val_loss: 1.4586 - val_accuracy: 0.4264\n",
            "Epoch 330/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7275 - accuracy: 0.6612 - val_loss: 1.4432 - val_accuracy: 0.4315\n",
            "Epoch 331/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7269 - accuracy: 0.6606 - val_loss: 1.4650 - val_accuracy: 0.4357\n",
            "Epoch 332/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7267 - accuracy: 0.6604 - val_loss: 1.4610 - val_accuracy: 0.4222\n",
            "Epoch 333/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7268 - accuracy: 0.6604 - val_loss: 1.4867 - val_accuracy: 0.4295\n",
            "Epoch 334/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7269 - accuracy: 0.6609 - val_loss: 1.4883 - val_accuracy: 0.4345\n",
            "Epoch 335/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7272 - accuracy: 0.6610 - val_loss: 1.4837 - val_accuracy: 0.4342\n",
            "Epoch 336/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7268 - accuracy: 0.6616 - val_loss: 1.4887 - val_accuracy: 0.4358\n",
            "Epoch 337/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7262 - accuracy: 0.6610 - val_loss: 1.4489 - val_accuracy: 0.4288\n",
            "Epoch 338/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7252 - accuracy: 0.6629 - val_loss: 1.4963 - val_accuracy: 0.4363\n",
            "Epoch 339/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7263 - accuracy: 0.6622 - val_loss: 1.4827 - val_accuracy: 0.4329\n",
            "Epoch 340/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7257 - accuracy: 0.6616 - val_loss: 1.4707 - val_accuracy: 0.4342\n",
            "Epoch 341/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7254 - accuracy: 0.6607 - val_loss: 1.4652 - val_accuracy: 0.4315\n",
            "Epoch 342/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7263 - accuracy: 0.6618 - val_loss: 1.4769 - val_accuracy: 0.4329\n",
            "Epoch 343/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7255 - accuracy: 0.6618 - val_loss: 1.4354 - val_accuracy: 0.4256\n",
            "Epoch 344/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7249 - accuracy: 0.6620 - val_loss: 1.4968 - val_accuracy: 0.4156\n",
            "Epoch 345/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7252 - accuracy: 0.6634 - val_loss: 1.4731 - val_accuracy: 0.4322\n",
            "Epoch 346/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7251 - accuracy: 0.6618 - val_loss: 1.4747 - val_accuracy: 0.4260\n",
            "Epoch 347/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7246 - accuracy: 0.6618 - val_loss: 1.4409 - val_accuracy: 0.4254\n",
            "Epoch 348/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7250 - accuracy: 0.6630 - val_loss: 1.4702 - val_accuracy: 0.4266\n",
            "Epoch 349/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7243 - accuracy: 0.6624 - val_loss: 1.4541 - val_accuracy: 0.4349\n",
            "Epoch 350/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7248 - accuracy: 0.6621 - val_loss: 1.4912 - val_accuracy: 0.4311\n",
            "Epoch 351/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7243 - accuracy: 0.6620 - val_loss: 1.5070 - val_accuracy: 0.4450\n",
            "Epoch 352/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7248 - accuracy: 0.6629 - val_loss: 1.4665 - val_accuracy: 0.4384\n",
            "Epoch 353/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7242 - accuracy: 0.6633 - val_loss: 1.5000 - val_accuracy: 0.4295\n",
            "Epoch 354/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7250 - accuracy: 0.6619 - val_loss: 1.4817 - val_accuracy: 0.4353\n",
            "Epoch 355/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7237 - accuracy: 0.6636 - val_loss: 1.4773 - val_accuracy: 0.4302\n",
            "Epoch 356/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7242 - accuracy: 0.6629 - val_loss: 1.4810 - val_accuracy: 0.4360\n",
            "Epoch 357/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7241 - accuracy: 0.6646 - val_loss: 1.4985 - val_accuracy: 0.4328\n",
            "Epoch 358/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7241 - accuracy: 0.6643 - val_loss: 1.4687 - val_accuracy: 0.4280\n",
            "Epoch 359/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7236 - accuracy: 0.6638 - val_loss: 1.4810 - val_accuracy: 0.4284\n",
            "Epoch 360/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7236 - accuracy: 0.6629 - val_loss: 1.4624 - val_accuracy: 0.4359\n",
            "Epoch 361/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7221 - accuracy: 0.6643 - val_loss: 1.5127 - val_accuracy: 0.4400\n",
            "Epoch 362/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7236 - accuracy: 0.6641 - val_loss: 1.4759 - val_accuracy: 0.4328\n",
            "Epoch 363/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7232 - accuracy: 0.6624 - val_loss: 1.4751 - val_accuracy: 0.4304\n",
            "Epoch 364/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7231 - accuracy: 0.6643 - val_loss: 1.5096 - val_accuracy: 0.4366\n",
            "Epoch 365/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7234 - accuracy: 0.6642 - val_loss: 1.4834 - val_accuracy: 0.4309\n",
            "Epoch 366/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7220 - accuracy: 0.6648 - val_loss: 1.4760 - val_accuracy: 0.4259\n",
            "Epoch 367/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7236 - accuracy: 0.6625 - val_loss: 1.5025 - val_accuracy: 0.4413\n",
            "Epoch 368/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7225 - accuracy: 0.6646 - val_loss: 1.5007 - val_accuracy: 0.4268\n",
            "Epoch 369/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7234 - accuracy: 0.6621 - val_loss: 1.5116 - val_accuracy: 0.4343\n",
            "Epoch 370/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7222 - accuracy: 0.6640 - val_loss: 1.4780 - val_accuracy: 0.4316\n",
            "Epoch 371/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7223 - accuracy: 0.6643 - val_loss: 1.4966 - val_accuracy: 0.4322\n",
            "Epoch 372/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7226 - accuracy: 0.6650 - val_loss: 1.4982 - val_accuracy: 0.4388\n",
            "Epoch 373/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7223 - accuracy: 0.6652 - val_loss: 1.4806 - val_accuracy: 0.4342\n",
            "Epoch 374/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7224 - accuracy: 0.6628 - val_loss: 1.5056 - val_accuracy: 0.4365\n",
            "Epoch 375/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7224 - accuracy: 0.6640 - val_loss: 1.4710 - val_accuracy: 0.4211\n",
            "Epoch 376/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7222 - accuracy: 0.6642 - val_loss: 1.4864 - val_accuracy: 0.4376\n",
            "Epoch 377/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7215 - accuracy: 0.6652 - val_loss: 1.4959 - val_accuracy: 0.4348\n",
            "Epoch 378/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7215 - accuracy: 0.6651 - val_loss: 1.4728 - val_accuracy: 0.4298\n",
            "Epoch 379/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7212 - accuracy: 0.6648 - val_loss: 1.4825 - val_accuracy: 0.4319\n",
            "Epoch 380/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7214 - accuracy: 0.6646 - val_loss: 1.4798 - val_accuracy: 0.4291\n",
            "Epoch 381/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7217 - accuracy: 0.6650 - val_loss: 1.4693 - val_accuracy: 0.4316\n",
            "Epoch 382/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7215 - accuracy: 0.6643 - val_loss: 1.4814 - val_accuracy: 0.4391\n",
            "Epoch 383/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7213 - accuracy: 0.6641 - val_loss: 1.5094 - val_accuracy: 0.4317\n",
            "Epoch 384/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7217 - accuracy: 0.6649 - val_loss: 1.4748 - val_accuracy: 0.4269\n",
            "Epoch 385/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7216 - accuracy: 0.6637 - val_loss: 1.4962 - val_accuracy: 0.4329\n",
            "Epoch 386/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7211 - accuracy: 0.6655 - val_loss: 1.4659 - val_accuracy: 0.4259\n",
            "Epoch 387/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7210 - accuracy: 0.6649 - val_loss: 1.4897 - val_accuracy: 0.4359\n",
            "Epoch 388/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7212 - accuracy: 0.6656 - val_loss: 1.5128 - val_accuracy: 0.4358\n",
            "Epoch 389/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7201 - accuracy: 0.6654 - val_loss: 1.5264 - val_accuracy: 0.4369\n",
            "Epoch 390/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7201 - accuracy: 0.6646 - val_loss: 1.4936 - val_accuracy: 0.4285\n",
            "Epoch 391/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7202 - accuracy: 0.6662 - val_loss: 1.4849 - val_accuracy: 0.4269\n",
            "Epoch 392/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7205 - accuracy: 0.6667 - val_loss: 1.5156 - val_accuracy: 0.4366\n",
            "Epoch 393/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7210 - accuracy: 0.6653 - val_loss: 1.4837 - val_accuracy: 0.4341\n",
            "Epoch 394/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7208 - accuracy: 0.6648 - val_loss: 1.5004 - val_accuracy: 0.4349\n",
            "Epoch 395/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7202 - accuracy: 0.6668 - val_loss: 1.4972 - val_accuracy: 0.4411\n",
            "Epoch 396/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7203 - accuracy: 0.6671 - val_loss: 1.5191 - val_accuracy: 0.4326\n",
            "Epoch 397/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7192 - accuracy: 0.6672 - val_loss: 1.5181 - val_accuracy: 0.4309\n",
            "Epoch 398/400\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.7204 - accuracy: 0.6653 - val_loss: 1.5006 - val_accuracy: 0.4324\n",
            "Epoch 399/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7201 - accuracy: 0.6645 - val_loss: 1.5197 - val_accuracy: 0.4379\n",
            "Epoch 400/400\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7199 - accuracy: 0.6674 - val_loss: 1.4930 - val_accuracy: 0.4295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 1:\n",
        "- Data Gold\n",
        "- Preprocess: Normalize\n",
        "- Result: loss: loss: 0.6733 - accuracy: 0.6937 - val_loss: 1.5001 - val_accuracy: 0.4472\n",
        "---\n",
        "Test 2:\n",
        "- Data All\n",
        "- Preprocess: Normalize\n",
        "- Result: loss: 0.8859 - accuracy: 0.5541 - val_loss: 1.1344 - val_accuracy: 0.4660\n",
        "---\n",
        "Test 3:\n",
        "- Data All\n",
        "- Preprocess: Hot Encode\n",
        "- Result: loss: 0.7199 - accuracy: 0.6674 - val_loss: 1.4930 - val_accuracy: 0.4295\n",
        "---\n",
        "Test 4:\n",
        "- Data Gold\n",
        "- Preprocess: Hot Encode\n",
        "- Result: loss: 0.2675 - accuracy: 0.8913 - val_loss: 4.5428 - val_accuracy: 0.3985"
      ],
      "metadata": {
        "id": "0iLYhrho-vNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The argument being passed to each Dense layer (16) is the number of hidden\n",
        "units of the layer. A hidden unit is a dimension in the representation space of the layer.\n",
        "You may remember from chapter 2 that each such Dense layer with a relu activation\n",
        "implements the following chain of tensor operations:\n",
        "output = relu(dot(W, input) + b)\n",
        "Having 16 hidden units means the weight matrix W will have shape (input_dimension,\n",
        "16): the dot product with W will project the input data onto a 16-dimensional representation space (and then youll add the bias vector b and apply the relu operation)."
      ],
      "metadata": {
        "id": "V8-VTui9r5BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./models/model_db_20_layer_09_22_2022.h5')"
      ],
      "metadata": {
        "id": "FG38n5X6h29p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Detail**\n",
        "model.add(layers.Dense(4096, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "**Lu ti /models/model_db_09_22_2022.h5**\n",
        "\n",
        "**loss: 0.1897 - accuracy: 0.9276**\n",
        "\n",
        "**Model Summary:**\n",
        "\n",
        "dense_9 (Dense)             (None, 4096)              53248     \n",
        "                                                                 \n",
        "dense_10 (Dense)            (None, 4096)              16781312  \n",
        "                                                                 \n",
        "dense_11 (Dense)            (None, 3)                 12291 \n",
        "\n",
        "**Model Detail** 10 layers\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "**Lu ti /models/model_db_10_layer_09_22_2022.h5**\n",
        "\n",
        "**loss: 0.1173 - accuracy: 0.9577**\n",
        "\n",
        "**Model Summary:**\n",
        "\n",
        "Model: \"sequential_7\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " dense_31 (Dense)            (None, 32)                416       \n",
        "                                                                 \n",
        " dense_32 (Dense)            (None, 64)                2112      \n",
        "                                                                 \n",
        " dense_33 (Dense)            (None, 128)               8320      \n",
        "                                                                 \n",
        " dense_34 (Dense)            (None, 256)               33024     \n",
        "                                                                 \n",
        " dense_35 (Dense)            (None, 256)               65792     \n",
        "                                                                 \n",
        " dense_36 (Dense)            (None, 128)               32896     \n",
        "                                                                 \n",
        " dense_37 (Dense)            (None, 64)                8256      \n",
        "                                                                 \n",
        " dense_38 (Dense)            (None, 32)                2080      \n",
        "                                                                 \n",
        " dense_39 (Dense)            (None, 16)                528       \n",
        "                                                                 \n",
        " dense_40 (Dense)            (None, 3)                 51  \n"
      ],
      "metadata": {
        "id": "RjrS6Ppan11b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IDi6e4n6108l",
        "outputId": "328e5e82-2d3a-4af4-bbdc-342407bc0aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}