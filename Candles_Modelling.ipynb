{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwHDCrV4tSxdGBn1i4evIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phantom1502/Deep-Learning/blob/main/Candles_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M3ThaZGvEaZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c57bd93-53b6-4208-f2d5-a58ba12325df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "#Config drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xauusd_df = pd.read_csv(\"./data/train_XAUUSD.csv\")\n",
        "xauusd_data = xauusd_df[xauusd_df.columns[0:12]].to_numpy()\n",
        "xauusd_label = xauusd_df[xauusd_df.columns[12:15]].to_numpy()\n",
        "\n",
        "eurusd_df = pd.read_csv(\"./data/train_EURUSD.csv\")\n",
        "eurusd_data = eurusd_df[eurusd_df.columns[0:12]].to_numpy()\n",
        "eurusd_label = eurusd_df[eurusd_df.columns[12:15]].to_numpy()\n",
        "\n",
        "gbpusd_df = pd.read_csv(\"./data/train_GBPUSD.csv\")\n",
        "gbpusd_data = gbpusd_df[gbpusd_df.columns[0:12]].to_numpy()\n",
        "gbpusd_label = gbpusd_df[gbpusd_df.columns[12:15]].to_numpy()"
      ],
      "metadata": {
        "id": "EqXIog0XhR0j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normallize_price(data):\n",
        "    mean = data.mean(axis=1)\n",
        "    std = data\n",
        "    for i in range(len(data)):\n",
        "        mean = data[i].mean()\n",
        "        data[i] -= mean\n",
        "        std = data[i].std()\n",
        "        data[i] /= std\n",
        "    return data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "xauusd_data = normallize_price(xauusd_data)\n",
        "xauusd_label =  np.asarray(xauusd_label).astype('float32')\n",
        "\n",
        "eurusd_data = normallize_price(eurusd_data)\n",
        "eurusd_label =  np.asarray(eurusd_label).astype('float32')\n",
        "\n",
        "gbpusd_data = normallize_price(gbpusd_data)\n",
        "gbpusd_label =  np.asarray(gbpusd_label).astype('float32')\n",
        "\n",
        "data = np.concatenate((xauusd_data, eurusd_data, gbpusd_data), axis=0)\n",
        "label = np.concatenate((xauusd_label, eurusd_label, gbpusd_label), axis=0)\n",
        "\n",
        "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.20, shuffle = False)\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)"
      ],
      "metadata": {
        "id": "aPk6aX8uh0ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e2d962-23ab-45c7-8a72-085729c0bb90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(69472, 12)\n",
            "(17368, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(xauusd_data.shape[1],)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(data_train, label_train, epochs=400, batch_size=256, validation_data=[data_test, label_test])"
      ],
      "metadata": {
        "id": "iGiQUgyUkLWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac9d24b-9dc3-452a-f243-792e7faef195"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "272/272 [==============================] - 7s 19ms/step - loss: 0.9685 - accuracy: 0.5018 - val_loss: 0.9613 - val_accuracy: 0.5093\n",
            "Epoch 2/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9600 - accuracy: 0.5017 - val_loss: 0.9556 - val_accuracy: 0.5033\n",
            "Epoch 3/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9581 - accuracy: 0.5018 - val_loss: 0.9582 - val_accuracy: 0.5093\n",
            "Epoch 4/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9575 - accuracy: 0.5022 - val_loss: 0.9596 - val_accuracy: 0.5086\n",
            "Epoch 5/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.9562 - accuracy: 0.5016 - val_loss: 0.9595 - val_accuracy: 0.5093\n",
            "Epoch 6/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9558 - accuracy: 0.5029 - val_loss: 0.9623 - val_accuracy: 0.5035\n",
            "Epoch 7/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9550 - accuracy: 0.5018 - val_loss: 0.9568 - val_accuracy: 0.5093\n",
            "Epoch 8/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9546 - accuracy: 0.5033 - val_loss: 0.9557 - val_accuracy: 0.5056\n",
            "Epoch 9/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9538 - accuracy: 0.5027 - val_loss: 0.9633 - val_accuracy: 0.5093\n",
            "Epoch 10/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9536 - accuracy: 0.5023 - val_loss: 0.9550 - val_accuracy: 0.5082\n",
            "Epoch 11/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9529 - accuracy: 0.5015 - val_loss: 0.9595 - val_accuracy: 0.4952\n",
            "Epoch 12/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9524 - accuracy: 0.5023 - val_loss: 0.9564 - val_accuracy: 0.5092\n",
            "Epoch 13/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9519 - accuracy: 0.5027 - val_loss: 0.9643 - val_accuracy: 0.5021\n",
            "Epoch 14/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.9515 - accuracy: 0.5027 - val_loss: 0.9550 - val_accuracy: 0.5096\n",
            "Epoch 15/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9507 - accuracy: 0.5026 - val_loss: 0.9619 - val_accuracy: 0.5077\n",
            "Epoch 16/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9499 - accuracy: 0.5029 - val_loss: 0.9565 - val_accuracy: 0.5074\n",
            "Epoch 17/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9493 - accuracy: 0.5037 - val_loss: 0.9645 - val_accuracy: 0.5003\n",
            "Epoch 18/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.9481 - accuracy: 0.5025 - val_loss: 0.9745 - val_accuracy: 0.5084\n",
            "Epoch 19/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9476 - accuracy: 0.5029 - val_loss: 0.9594 - val_accuracy: 0.5090\n",
            "Epoch 20/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9472 - accuracy: 0.5032 - val_loss: 0.9667 - val_accuracy: 0.5055\n",
            "Epoch 21/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9462 - accuracy: 0.5044 - val_loss: 0.9626 - val_accuracy: 0.5048\n",
            "Epoch 22/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9454 - accuracy: 0.5047 - val_loss: 0.9651 - val_accuracy: 0.5039\n",
            "Epoch 23/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9445 - accuracy: 0.5046 - val_loss: 0.9612 - val_accuracy: 0.5054\n",
            "Epoch 24/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9430 - accuracy: 0.5059 - val_loss: 0.9623 - val_accuracy: 0.5090\n",
            "Epoch 25/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9427 - accuracy: 0.5030 - val_loss: 0.9631 - val_accuracy: 0.5073\n",
            "Epoch 26/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9414 - accuracy: 0.5030 - val_loss: 0.9660 - val_accuracy: 0.5041\n",
            "Epoch 27/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9406 - accuracy: 0.5049 - val_loss: 0.9652 - val_accuracy: 0.5082\n",
            "Epoch 28/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9390 - accuracy: 0.5054 - val_loss: 0.9661 - val_accuracy: 0.5038\n",
            "Epoch 29/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9380 - accuracy: 0.5045 - val_loss: 0.9756 - val_accuracy: 0.4891\n",
            "Epoch 30/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9361 - accuracy: 0.5073 - val_loss: 0.9711 - val_accuracy: 0.4996\n",
            "Epoch 31/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9347 - accuracy: 0.5083 - val_loss: 0.9797 - val_accuracy: 0.5066\n",
            "Epoch 32/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9336 - accuracy: 0.5082 - val_loss: 0.9734 - val_accuracy: 0.4987\n",
            "Epoch 33/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9314 - accuracy: 0.5103 - val_loss: 0.9894 - val_accuracy: 0.5062\n",
            "Epoch 34/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9298 - accuracy: 0.5111 - val_loss: 0.9825 - val_accuracy: 0.4967\n",
            "Epoch 35/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9281 - accuracy: 0.5107 - val_loss: 1.0033 - val_accuracy: 0.4968\n",
            "Epoch 36/400\n",
            "272/272 [==============================] - 6s 21ms/step - loss: 0.9262 - accuracy: 0.5137 - val_loss: 0.9781 - val_accuracy: 0.4861\n",
            "Epoch 37/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.9237 - accuracy: 0.5145 - val_loss: 0.9843 - val_accuracy: 0.4892\n",
            "Epoch 38/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9223 - accuracy: 0.5163 - val_loss: 1.0023 - val_accuracy: 0.4779\n",
            "Epoch 39/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9195 - accuracy: 0.5186 - val_loss: 0.9958 - val_accuracy: 0.4849\n",
            "Epoch 40/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9166 - accuracy: 0.5211 - val_loss: 1.0107 - val_accuracy: 0.4794\n",
            "Epoch 41/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9140 - accuracy: 0.5210 - val_loss: 1.0370 - val_accuracy: 0.5004\n",
            "Epoch 42/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9118 - accuracy: 0.5237 - val_loss: 1.0151 - val_accuracy: 0.4846\n",
            "Epoch 43/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9097 - accuracy: 0.5247 - val_loss: 1.0312 - val_accuracy: 0.4908\n",
            "Epoch 44/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9059 - accuracy: 0.5287 - val_loss: 1.0165 - val_accuracy: 0.4919\n",
            "Epoch 45/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.9025 - accuracy: 0.5287 - val_loss: 1.0295 - val_accuracy: 0.4917\n",
            "Epoch 46/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8996 - accuracy: 0.5319 - val_loss: 1.0539 - val_accuracy: 0.4837\n",
            "Epoch 47/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8968 - accuracy: 0.5358 - val_loss: 1.0683 - val_accuracy: 0.4680\n",
            "Epoch 48/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8915 - accuracy: 0.5366 - val_loss: 1.0248 - val_accuracy: 0.4900\n",
            "Epoch 49/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8894 - accuracy: 0.5402 - val_loss: 1.0369 - val_accuracy: 0.4832\n",
            "Epoch 50/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8865 - accuracy: 0.5400 - val_loss: 1.0818 - val_accuracy: 0.4796\n",
            "Epoch 51/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8823 - accuracy: 0.5426 - val_loss: 1.0615 - val_accuracy: 0.4693\n",
            "Epoch 52/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8809 - accuracy: 0.5455 - val_loss: 1.0384 - val_accuracy: 0.4877\n",
            "Epoch 53/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8751 - accuracy: 0.5489 - val_loss: 1.1349 - val_accuracy: 0.4825\n",
            "Epoch 54/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8722 - accuracy: 0.5505 - val_loss: 1.0850 - val_accuracy: 0.4763\n",
            "Epoch 55/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8679 - accuracy: 0.5547 - val_loss: 1.0552 - val_accuracy: 0.4676\n",
            "Epoch 56/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8641 - accuracy: 0.5566 - val_loss: 1.0944 - val_accuracy: 0.4755\n",
            "Epoch 57/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8608 - accuracy: 0.5573 - val_loss: 1.1074 - val_accuracy: 0.4635\n",
            "Epoch 58/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8568 - accuracy: 0.5601 - val_loss: 1.1016 - val_accuracy: 0.4618\n",
            "Epoch 59/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8522 - accuracy: 0.5649 - val_loss: 1.1304 - val_accuracy: 0.4719\n",
            "Epoch 60/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8497 - accuracy: 0.5647 - val_loss: 1.1322 - val_accuracy: 0.4701\n",
            "Epoch 61/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8457 - accuracy: 0.5674 - val_loss: 1.1318 - val_accuracy: 0.4720\n",
            "Epoch 62/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8408 - accuracy: 0.5706 - val_loss: 1.1014 - val_accuracy: 0.4697\n",
            "Epoch 63/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8393 - accuracy: 0.5726 - val_loss: 1.1967 - val_accuracy: 0.4556\n",
            "Epoch 64/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8349 - accuracy: 0.5735 - val_loss: 1.2075 - val_accuracy: 0.4416\n",
            "Epoch 65/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8318 - accuracy: 0.5746 - val_loss: 1.1668 - val_accuracy: 0.4652\n",
            "Epoch 66/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8261 - accuracy: 0.5782 - val_loss: 1.1699 - val_accuracy: 0.4492\n",
            "Epoch 67/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8224 - accuracy: 0.5812 - val_loss: 1.1604 - val_accuracy: 0.4607\n",
            "Epoch 68/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8195 - accuracy: 0.5828 - val_loss: 1.1888 - val_accuracy: 0.4720\n",
            "Epoch 69/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.8131 - accuracy: 0.5865 - val_loss: 1.2529 - val_accuracy: 0.4541\n",
            "Epoch 70/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.8079 - accuracy: 0.5903 - val_loss: 1.2179 - val_accuracy: 0.4578\n",
            "Epoch 71/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.8095 - accuracy: 0.5885 - val_loss: 1.2249 - val_accuracy: 0.4575\n",
            "Epoch 72/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.8011 - accuracy: 0.5920 - val_loss: 1.2597 - val_accuracy: 0.4723\n",
            "Epoch 73/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7994 - accuracy: 0.5930 - val_loss: 1.2751 - val_accuracy: 0.4437\n",
            "Epoch 74/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7941 - accuracy: 0.5959 - val_loss: 1.3185 - val_accuracy: 0.4394\n",
            "Epoch 75/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7880 - accuracy: 0.5992 - val_loss: 1.2585 - val_accuracy: 0.4683\n",
            "Epoch 76/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7869 - accuracy: 0.6010 - val_loss: 1.3189 - val_accuracy: 0.4668\n",
            "Epoch 77/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7830 - accuracy: 0.6025 - val_loss: 1.2709 - val_accuracy: 0.4598\n",
            "Epoch 78/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7783 - accuracy: 0.6064 - val_loss: 1.2774 - val_accuracy: 0.4435\n",
            "Epoch 79/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.7736 - accuracy: 0.6069 - val_loss: 1.3069 - val_accuracy: 0.4644\n",
            "Epoch 80/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.7713 - accuracy: 0.6107 - val_loss: 1.3465 - val_accuracy: 0.4654\n",
            "Epoch 81/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7675 - accuracy: 0.6125 - val_loss: 1.2263 - val_accuracy: 0.4555\n",
            "Epoch 82/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7621 - accuracy: 0.6147 - val_loss: 1.3097 - val_accuracy: 0.4653\n",
            "Epoch 83/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7583 - accuracy: 0.6179 - val_loss: 1.3227 - val_accuracy: 0.4500\n",
            "Epoch 84/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7553 - accuracy: 0.6198 - val_loss: 1.4678 - val_accuracy: 0.4645\n",
            "Epoch 85/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7521 - accuracy: 0.6210 - val_loss: 1.4606 - val_accuracy: 0.4663\n",
            "Epoch 86/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7475 - accuracy: 0.6218 - val_loss: 1.3706 - val_accuracy: 0.4554\n",
            "Epoch 87/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7420 - accuracy: 0.6258 - val_loss: 1.4267 - val_accuracy: 0.4544\n",
            "Epoch 88/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.7394 - accuracy: 0.6266 - val_loss: 1.4059 - val_accuracy: 0.4285\n",
            "Epoch 89/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7346 - accuracy: 0.6297 - val_loss: 1.4279 - val_accuracy: 0.4522\n",
            "Epoch 90/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7312 - accuracy: 0.6329 - val_loss: 1.5325 - val_accuracy: 0.4499\n",
            "Epoch 91/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7332 - accuracy: 0.6318 - val_loss: 1.4837 - val_accuracy: 0.4459\n",
            "Epoch 92/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7249 - accuracy: 0.6336 - val_loss: 1.5790 - val_accuracy: 0.4409\n",
            "Epoch 93/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7230 - accuracy: 0.6370 - val_loss: 1.4408 - val_accuracy: 0.4554\n",
            "Epoch 94/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7165 - accuracy: 0.6386 - val_loss: 1.4393 - val_accuracy: 0.4501\n",
            "Epoch 95/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7119 - accuracy: 0.6415 - val_loss: 1.5422 - val_accuracy: 0.4627\n",
            "Epoch 96/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7109 - accuracy: 0.6432 - val_loss: 1.5521 - val_accuracy: 0.4532\n",
            "Epoch 97/400\n",
            "272/272 [==============================] - 5s 17ms/step - loss: 0.7079 - accuracy: 0.6441 - val_loss: 1.4271 - val_accuracy: 0.4440\n",
            "Epoch 98/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7029 - accuracy: 0.6472 - val_loss: 1.4191 - val_accuracy: 0.4394\n",
            "Epoch 99/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.7003 - accuracy: 0.6489 - val_loss: 1.5478 - val_accuracy: 0.4455\n",
            "Epoch 100/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6984 - accuracy: 0.6501 - val_loss: 1.6536 - val_accuracy: 0.4401\n",
            "Epoch 101/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6941 - accuracy: 0.6517 - val_loss: 1.5538 - val_accuracy: 0.4697\n",
            "Epoch 102/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6906 - accuracy: 0.6545 - val_loss: 1.5888 - val_accuracy: 0.4375\n",
            "Epoch 103/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6843 - accuracy: 0.6569 - val_loss: 1.5241 - val_accuracy: 0.4589\n",
            "Epoch 104/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6823 - accuracy: 0.6584 - val_loss: 1.5654 - val_accuracy: 0.4255\n",
            "Epoch 105/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6815 - accuracy: 0.6586 - val_loss: 1.8277 - val_accuracy: 0.4301\n",
            "Epoch 106/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6750 - accuracy: 0.6609 - val_loss: 1.7282 - val_accuracy: 0.4471\n",
            "Epoch 107/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6710 - accuracy: 0.6655 - val_loss: 1.6313 - val_accuracy: 0.4368\n",
            "Epoch 108/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6702 - accuracy: 0.6665 - val_loss: 1.8210 - val_accuracy: 0.4417\n",
            "Epoch 109/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6665 - accuracy: 0.6647 - val_loss: 1.9185 - val_accuracy: 0.4655\n",
            "Epoch 110/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6625 - accuracy: 0.6686 - val_loss: 1.9204 - val_accuracy: 0.4433\n",
            "Epoch 111/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6613 - accuracy: 0.6694 - val_loss: 1.9009 - val_accuracy: 0.4421\n",
            "Epoch 112/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6593 - accuracy: 0.6728 - val_loss: 1.6396 - val_accuracy: 0.4418\n",
            "Epoch 113/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6551 - accuracy: 0.6732 - val_loss: 1.9163 - val_accuracy: 0.4557\n",
            "Epoch 114/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6519 - accuracy: 0.6743 - val_loss: 1.7254 - val_accuracy: 0.4392\n",
            "Epoch 115/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6491 - accuracy: 0.6776 - val_loss: 1.7884 - val_accuracy: 0.4436\n",
            "Epoch 116/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6458 - accuracy: 0.6779 - val_loss: 1.7824 - val_accuracy: 0.4511\n",
            "Epoch 117/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6469 - accuracy: 0.6794 - val_loss: 1.7919 - val_accuracy: 0.4526\n",
            "Epoch 118/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6403 - accuracy: 0.6818 - val_loss: 1.7787 - val_accuracy: 0.4408\n",
            "Epoch 119/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6372 - accuracy: 0.6829 - val_loss: 1.7611 - val_accuracy: 0.4500\n",
            "Epoch 120/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6314 - accuracy: 0.6852 - val_loss: 1.9151 - val_accuracy: 0.4400\n",
            "Epoch 121/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6310 - accuracy: 0.6853 - val_loss: 1.8957 - val_accuracy: 0.4253\n",
            "Epoch 122/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6295 - accuracy: 0.6897 - val_loss: 1.8171 - val_accuracy: 0.4500\n",
            "Epoch 123/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6280 - accuracy: 0.6901 - val_loss: 1.9590 - val_accuracy: 0.4486\n",
            "Epoch 124/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.6209 - accuracy: 0.6938 - val_loss: 2.1512 - val_accuracy: 0.4401\n",
            "Epoch 125/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6191 - accuracy: 0.6951 - val_loss: 2.0581 - val_accuracy: 0.4302\n",
            "Epoch 126/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6142 - accuracy: 0.6975 - val_loss: 1.9397 - val_accuracy: 0.4472\n",
            "Epoch 127/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6145 - accuracy: 0.6948 - val_loss: 1.9239 - val_accuracy: 0.4394\n",
            "Epoch 128/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6118 - accuracy: 0.6962 - val_loss: 1.8141 - val_accuracy: 0.4385\n",
            "Epoch 129/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6055 - accuracy: 0.7002 - val_loss: 2.0020 - val_accuracy: 0.4561\n",
            "Epoch 130/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6050 - accuracy: 0.7003 - val_loss: 1.9820 - val_accuracy: 0.4613\n",
            "Epoch 131/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.6018 - accuracy: 0.7025 - val_loss: 1.9346 - val_accuracy: 0.4421\n",
            "Epoch 132/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5996 - accuracy: 0.7044 - val_loss: 1.8723 - val_accuracy: 0.4234\n",
            "Epoch 133/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5993 - accuracy: 0.7044 - val_loss: 2.0273 - val_accuracy: 0.4366\n",
            "Epoch 134/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5990 - accuracy: 0.7061 - val_loss: 2.0080 - val_accuracy: 0.4306\n",
            "Epoch 135/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5904 - accuracy: 0.7070 - val_loss: 2.2206 - val_accuracy: 0.4285\n",
            "Epoch 136/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5909 - accuracy: 0.7092 - val_loss: 2.1378 - val_accuracy: 0.4342\n",
            "Epoch 137/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5870 - accuracy: 0.7125 - val_loss: 2.1349 - val_accuracy: 0.4334\n",
            "Epoch 138/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5841 - accuracy: 0.7135 - val_loss: 1.9581 - val_accuracy: 0.4291\n",
            "Epoch 139/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5829 - accuracy: 0.7137 - val_loss: 2.2602 - val_accuracy: 0.4335\n",
            "Epoch 140/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5797 - accuracy: 0.7158 - val_loss: 2.1502 - val_accuracy: 0.4409\n",
            "Epoch 141/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5766 - accuracy: 0.7158 - val_loss: 2.3895 - val_accuracy: 0.4467\n",
            "Epoch 142/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5756 - accuracy: 0.7170 - val_loss: 2.0914 - val_accuracy: 0.4503\n",
            "Epoch 143/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5725 - accuracy: 0.7198 - val_loss: 2.1680 - val_accuracy: 0.4505\n",
            "Epoch 144/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5673 - accuracy: 0.7214 - val_loss: 2.4123 - val_accuracy: 0.4530\n",
            "Epoch 145/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5643 - accuracy: 0.7229 - val_loss: 2.1715 - val_accuracy: 0.4281\n",
            "Epoch 146/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5629 - accuracy: 0.7255 - val_loss: 2.2009 - val_accuracy: 0.4234\n",
            "Epoch 147/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5634 - accuracy: 0.7246 - val_loss: 2.1781 - val_accuracy: 0.4283\n",
            "Epoch 148/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5616 - accuracy: 0.7241 - val_loss: 2.1373 - val_accuracy: 0.4251\n",
            "Epoch 149/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5575 - accuracy: 0.7278 - val_loss: 2.3776 - val_accuracy: 0.4371\n",
            "Epoch 150/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5548 - accuracy: 0.7301 - val_loss: 2.1612 - val_accuracy: 0.4289\n",
            "Epoch 151/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5505 - accuracy: 0.7304 - val_loss: 2.1836 - val_accuracy: 0.4402\n",
            "Epoch 152/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5481 - accuracy: 0.7322 - val_loss: 2.2958 - val_accuracy: 0.4317\n",
            "Epoch 153/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5505 - accuracy: 0.7335 - val_loss: 2.4188 - val_accuracy: 0.4394\n",
            "Epoch 154/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5464 - accuracy: 0.7350 - val_loss: 2.3610 - val_accuracy: 0.4464\n",
            "Epoch 155/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5425 - accuracy: 0.7362 - val_loss: 2.2616 - val_accuracy: 0.4448\n",
            "Epoch 156/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5413 - accuracy: 0.7379 - val_loss: 2.2894 - val_accuracy: 0.4258\n",
            "Epoch 157/400\n",
            "272/272 [==============================] - 4s 15ms/step - loss: 0.5384 - accuracy: 0.7374 - val_loss: 2.3283 - val_accuracy: 0.4248\n",
            "Epoch 158/400\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.5373 - accuracy: 0.7382 - val_loss: 2.1943 - val_accuracy: 0.4369\n",
            "Epoch 159/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5343 - accuracy: 0.7395 - val_loss: 2.1812 - val_accuracy: 0.4364\n",
            "Epoch 160/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5330 - accuracy: 0.7392 - val_loss: 2.2941 - val_accuracy: 0.4223\n",
            "Epoch 161/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5308 - accuracy: 0.7432 - val_loss: 2.1476 - val_accuracy: 0.4147\n",
            "Epoch 162/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5277 - accuracy: 0.7464 - val_loss: 2.5322 - val_accuracy: 0.4158\n",
            "Epoch 163/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5246 - accuracy: 0.7456 - val_loss: 2.3312 - val_accuracy: 0.4308\n",
            "Epoch 164/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5240 - accuracy: 0.7439 - val_loss: 2.6189 - val_accuracy: 0.4368\n",
            "Epoch 165/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5233 - accuracy: 0.7489 - val_loss: 2.5131 - val_accuracy: 0.4345\n",
            "Epoch 166/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5191 - accuracy: 0.7467 - val_loss: 2.2522 - val_accuracy: 0.4323\n",
            "Epoch 167/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5168 - accuracy: 0.7490 - val_loss: 2.3861 - val_accuracy: 0.4280\n",
            "Epoch 168/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5150 - accuracy: 0.7518 - val_loss: 2.3829 - val_accuracy: 0.4317\n",
            "Epoch 169/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5139 - accuracy: 0.7517 - val_loss: 2.4301 - val_accuracy: 0.4251\n",
            "Epoch 170/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5111 - accuracy: 0.7525 - val_loss: 2.4713 - val_accuracy: 0.4288\n",
            "Epoch 171/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5081 - accuracy: 0.7552 - val_loss: 2.6131 - val_accuracy: 0.4395\n",
            "Epoch 172/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5067 - accuracy: 0.7558 - val_loss: 2.5304 - val_accuracy: 0.4257\n",
            "Epoch 173/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5050 - accuracy: 0.7556 - val_loss: 2.6725 - val_accuracy: 0.4318\n",
            "Epoch 174/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5031 - accuracy: 0.7578 - val_loss: 2.3361 - val_accuracy: 0.4350\n",
            "Epoch 175/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.5051 - accuracy: 0.7582 - val_loss: 2.6528 - val_accuracy: 0.4463\n",
            "Epoch 176/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5018 - accuracy: 0.7596 - val_loss: 2.4270 - val_accuracy: 0.4382\n",
            "Epoch 177/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.5051 - accuracy: 0.7608 - val_loss: 2.6827 - val_accuracy: 0.4282\n",
            "Epoch 178/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4947 - accuracy: 0.7614 - val_loss: 2.8676 - val_accuracy: 0.4374\n",
            "Epoch 179/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4946 - accuracy: 0.7629 - val_loss: 2.5132 - val_accuracy: 0.4287\n",
            "Epoch 180/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4904 - accuracy: 0.7643 - val_loss: 2.7441 - val_accuracy: 0.4224\n",
            "Epoch 181/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4866 - accuracy: 0.7655 - val_loss: 2.8988 - val_accuracy: 0.4250\n",
            "Epoch 182/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4884 - accuracy: 0.7671 - val_loss: 2.7310 - val_accuracy: 0.4182\n",
            "Epoch 183/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4879 - accuracy: 0.7662 - val_loss: 2.6226 - val_accuracy: 0.4140\n",
            "Epoch 184/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4830 - accuracy: 0.7685 - val_loss: 2.9609 - val_accuracy: 0.4289\n",
            "Epoch 185/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4804 - accuracy: 0.7698 - val_loss: 2.7910 - val_accuracy: 0.4344\n",
            "Epoch 186/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4823 - accuracy: 0.7713 - val_loss: 2.5015 - val_accuracy: 0.4145\n",
            "Epoch 187/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4757 - accuracy: 0.7728 - val_loss: 3.1987 - val_accuracy: 0.4230\n",
            "Epoch 188/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4817 - accuracy: 0.7692 - val_loss: 2.4689 - val_accuracy: 0.4308\n",
            "Epoch 189/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4734 - accuracy: 0.7765 - val_loss: 2.9739 - val_accuracy: 0.4183\n",
            "Epoch 190/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4761 - accuracy: 0.7724 - val_loss: 2.4652 - val_accuracy: 0.4160\n",
            "Epoch 191/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4696 - accuracy: 0.7754 - val_loss: 2.5744 - val_accuracy: 0.4156\n",
            "Epoch 192/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4725 - accuracy: 0.7752 - val_loss: 3.0689 - val_accuracy: 0.4435\n",
            "Epoch 193/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4706 - accuracy: 0.7758 - val_loss: 2.6309 - val_accuracy: 0.4284\n",
            "Epoch 194/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4669 - accuracy: 0.7788 - val_loss: 2.8189 - val_accuracy: 0.4342\n",
            "Epoch 195/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 2.6609 - val_accuracy: 0.4094\n",
            "Epoch 196/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4639 - accuracy: 0.7796 - val_loss: 2.8709 - val_accuracy: 0.4236\n",
            "Epoch 197/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4642 - accuracy: 0.7800 - val_loss: 2.6806 - val_accuracy: 0.4362\n",
            "Epoch 198/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4645 - accuracy: 0.7803 - val_loss: 2.6566 - val_accuracy: 0.4164\n",
            "Epoch 199/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 2.8594 - val_accuracy: 0.4327\n",
            "Epoch 200/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4607 - accuracy: 0.7832 - val_loss: 2.6772 - val_accuracy: 0.4317\n",
            "Epoch 201/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4521 - accuracy: 0.7857 - val_loss: 2.9156 - val_accuracy: 0.4338\n",
            "Epoch 202/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4535 - accuracy: 0.7878 - val_loss: 2.6646 - val_accuracy: 0.4089\n",
            "Epoch 203/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4529 - accuracy: 0.7856 - val_loss: 2.9786 - val_accuracy: 0.4353\n",
            "Epoch 204/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4546 - accuracy: 0.7869 - val_loss: 2.7956 - val_accuracy: 0.4306\n",
            "Epoch 205/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 3.0342 - val_accuracy: 0.4349\n",
            "Epoch 206/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4465 - accuracy: 0.7912 - val_loss: 2.7572 - val_accuracy: 0.4330\n",
            "Epoch 207/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4461 - accuracy: 0.7910 - val_loss: 2.8972 - val_accuracy: 0.4246\n",
            "Epoch 208/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4427 - accuracy: 0.7901 - val_loss: 3.0110 - val_accuracy: 0.4329\n",
            "Epoch 209/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4440 - accuracy: 0.7914 - val_loss: 2.9157 - val_accuracy: 0.4395\n",
            "Epoch 210/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4439 - accuracy: 0.7906 - val_loss: 2.7523 - val_accuracy: 0.4359\n",
            "Epoch 211/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4383 - accuracy: 0.7943 - val_loss: 2.9345 - val_accuracy: 0.4302\n",
            "Epoch 212/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4364 - accuracy: 0.7928 - val_loss: 2.9742 - val_accuracy: 0.4313\n",
            "Epoch 213/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4369 - accuracy: 0.7959 - val_loss: 3.4715 - val_accuracy: 0.4361\n",
            "Epoch 214/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4343 - accuracy: 0.7955 - val_loss: 2.9965 - val_accuracy: 0.4230\n",
            "Epoch 215/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4326 - accuracy: 0.7968 - val_loss: 3.1330 - val_accuracy: 0.4288\n",
            "Epoch 216/400\n",
            "272/272 [==============================] - 4s 15ms/step - loss: 0.4334 - accuracy: 0.7959 - val_loss: 3.2070 - val_accuracy: 0.4225\n",
            "Epoch 217/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.4349 - accuracy: 0.7956 - val_loss: 3.0726 - val_accuracy: 0.4294\n",
            "Epoch 218/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4282 - accuracy: 0.7984 - val_loss: 2.9790 - val_accuracy: 0.4221\n",
            "Epoch 219/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4282 - accuracy: 0.7997 - val_loss: 2.9232 - val_accuracy: 0.4200\n",
            "Epoch 220/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 3.0301 - val_accuracy: 0.4347\n",
            "Epoch 221/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4246 - accuracy: 0.8015 - val_loss: 2.7718 - val_accuracy: 0.4260\n",
            "Epoch 222/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4229 - accuracy: 0.8031 - val_loss: 3.1375 - val_accuracy: 0.4371\n",
            "Epoch 223/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4225 - accuracy: 0.8024 - val_loss: 2.8943 - val_accuracy: 0.4485\n",
            "Epoch 224/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4222 - accuracy: 0.8030 - val_loss: 3.0358 - val_accuracy: 0.4261\n",
            "Epoch 225/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4211 - accuracy: 0.8019 - val_loss: 3.0861 - val_accuracy: 0.4204\n",
            "Epoch 226/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 3.4115 - val_accuracy: 0.4234\n",
            "Epoch 227/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4160 - accuracy: 0.8056 - val_loss: 3.1968 - val_accuracy: 0.4030\n",
            "Epoch 228/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4164 - accuracy: 0.8067 - val_loss: 3.0886 - val_accuracy: 0.4282\n",
            "Epoch 229/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4155 - accuracy: 0.8054 - val_loss: 3.1312 - val_accuracy: 0.4231\n",
            "Epoch 230/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4159 - accuracy: 0.8064 - val_loss: 3.0172 - val_accuracy: 0.4199\n",
            "Epoch 231/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4112 - accuracy: 0.8084 - val_loss: 3.4354 - val_accuracy: 0.4323\n",
            "Epoch 232/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4107 - accuracy: 0.8081 - val_loss: 2.8225 - val_accuracy: 0.4163\n",
            "Epoch 233/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4103 - accuracy: 0.8102 - val_loss: 3.3571 - val_accuracy: 0.4196\n",
            "Epoch 234/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4078 - accuracy: 0.8087 - val_loss: 3.3178 - val_accuracy: 0.4384\n",
            "Epoch 235/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4052 - accuracy: 0.8102 - val_loss: 3.2679 - val_accuracy: 0.4283\n",
            "Epoch 236/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4111 - accuracy: 0.8095 - val_loss: 3.1340 - val_accuracy: 0.4345\n",
            "Epoch 237/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4065 - accuracy: 0.8107 - val_loss: 3.1079 - val_accuracy: 0.4311\n",
            "Epoch 238/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4055 - accuracy: 0.8129 - val_loss: 3.2601 - val_accuracy: 0.4192\n",
            "Epoch 239/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4065 - accuracy: 0.8119 - val_loss: 3.0988 - val_accuracy: 0.4363\n",
            "Epoch 240/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.4018 - accuracy: 0.8145 - val_loss: 3.0881 - val_accuracy: 0.4180\n",
            "Epoch 241/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3988 - accuracy: 0.8141 - val_loss: 3.2890 - val_accuracy: 0.4264\n",
            "Epoch 242/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4007 - accuracy: 0.8150 - val_loss: 3.2330 - val_accuracy: 0.4279\n",
            "Epoch 243/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3978 - accuracy: 0.8154 - val_loss: 3.1393 - val_accuracy: 0.4253\n",
            "Epoch 244/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3942 - accuracy: 0.8181 - val_loss: 3.1641 - val_accuracy: 0.4223\n",
            "Epoch 245/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4027 - accuracy: 0.8153 - val_loss: 3.3034 - val_accuracy: 0.4237\n",
            "Epoch 246/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3945 - accuracy: 0.8183 - val_loss: 3.0857 - val_accuracy: 0.4304\n",
            "Epoch 247/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3913 - accuracy: 0.8177 - val_loss: 3.5313 - val_accuracy: 0.4235\n",
            "Epoch 248/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3947 - accuracy: 0.8183 - val_loss: 3.2228 - val_accuracy: 0.4253\n",
            "Epoch 249/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3919 - accuracy: 0.8196 - val_loss: 3.2274 - val_accuracy: 0.4256\n",
            "Epoch 250/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3922 - accuracy: 0.8197 - val_loss: 2.9820 - val_accuracy: 0.4301\n",
            "Epoch 251/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3911 - accuracy: 0.8194 - val_loss: 3.2494 - val_accuracy: 0.4362\n",
            "Epoch 252/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3870 - accuracy: 0.8214 - val_loss: 3.4961 - val_accuracy: 0.4201\n",
            "Epoch 253/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3848 - accuracy: 0.8215 - val_loss: 3.5654 - val_accuracy: 0.4383\n",
            "Epoch 254/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3851 - accuracy: 0.8222 - val_loss: 3.8841 - val_accuracy: 0.4425\n",
            "Epoch 255/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3832 - accuracy: 0.8228 - val_loss: 3.3505 - val_accuracy: 0.4291\n",
            "Epoch 256/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3840 - accuracy: 0.8222 - val_loss: 3.6257 - val_accuracy: 0.4205\n",
            "Epoch 257/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3857 - accuracy: 0.8231 - val_loss: 3.4177 - val_accuracy: 0.4238\n",
            "Epoch 258/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3804 - accuracy: 0.8250 - val_loss: 3.6276 - val_accuracy: 0.4229\n",
            "Epoch 259/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3808 - accuracy: 0.8260 - val_loss: 3.6012 - val_accuracy: 0.4255\n",
            "Epoch 260/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3826 - accuracy: 0.8237 - val_loss: 3.3593 - val_accuracy: 0.4162\n",
            "Epoch 261/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3768 - accuracy: 0.8286 - val_loss: 3.5342 - val_accuracy: 0.4134\n",
            "Epoch 262/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3793 - accuracy: 0.8268 - val_loss: 3.5323 - val_accuracy: 0.4201\n",
            "Epoch 263/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3730 - accuracy: 0.8289 - val_loss: 3.5252 - val_accuracy: 0.4283\n",
            "Epoch 264/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3784 - accuracy: 0.8280 - val_loss: 3.5799 - val_accuracy: 0.4285\n",
            "Epoch 265/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3771 - accuracy: 0.8274 - val_loss: 3.4004 - val_accuracy: 0.4314\n",
            "Epoch 266/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3734 - accuracy: 0.8294 - val_loss: 3.5981 - val_accuracy: 0.4341\n",
            "Epoch 267/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3712 - accuracy: 0.8313 - val_loss: 3.8815 - val_accuracy: 0.4330\n",
            "Epoch 268/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3668 - accuracy: 0.8312 - val_loss: 3.8161 - val_accuracy: 0.4367\n",
            "Epoch 269/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3697 - accuracy: 0.8309 - val_loss: 3.3243 - val_accuracy: 0.4236\n",
            "Epoch 270/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3726 - accuracy: 0.8297 - val_loss: 3.3722 - val_accuracy: 0.4370\n",
            "Epoch 271/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3711 - accuracy: 0.8308 - val_loss: 3.2337 - val_accuracy: 0.4219\n",
            "Epoch 272/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3678 - accuracy: 0.8331 - val_loss: 3.7224 - val_accuracy: 0.4306\n",
            "Epoch 273/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3696 - accuracy: 0.8337 - val_loss: 3.3502 - val_accuracy: 0.4319\n",
            "Epoch 274/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3666 - accuracy: 0.8335 - val_loss: 3.4999 - val_accuracy: 0.4166\n",
            "Epoch 275/400\n",
            "272/272 [==============================] - 4s 16ms/step - loss: 0.3627 - accuracy: 0.8338 - val_loss: 3.8733 - val_accuracy: 0.4288\n",
            "Epoch 276/400\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.3646 - accuracy: 0.8339 - val_loss: 3.7379 - val_accuracy: 0.4260\n",
            "Epoch 277/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3618 - accuracy: 0.8358 - val_loss: 3.9153 - val_accuracy: 0.4260\n",
            "Epoch 278/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3615 - accuracy: 0.8357 - val_loss: 3.6284 - val_accuracy: 0.4171\n",
            "Epoch 279/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3632 - accuracy: 0.8352 - val_loss: 3.5050 - val_accuracy: 0.4230\n",
            "Epoch 280/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3615 - accuracy: 0.8370 - val_loss: 3.6064 - val_accuracy: 0.4245\n",
            "Epoch 281/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3635 - accuracy: 0.8360 - val_loss: 3.7220 - val_accuracy: 0.4236\n",
            "Epoch 282/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3577 - accuracy: 0.8386 - val_loss: 3.6999 - val_accuracy: 0.4226\n",
            "Epoch 283/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3573 - accuracy: 0.8370 - val_loss: 3.5694 - val_accuracy: 0.4236\n",
            "Epoch 284/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3577 - accuracy: 0.8382 - val_loss: 3.4306 - val_accuracy: 0.4253\n",
            "Epoch 285/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3542 - accuracy: 0.8403 - val_loss: 3.2388 - val_accuracy: 0.4283\n",
            "Epoch 286/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3557 - accuracy: 0.8393 - val_loss: 3.5317 - val_accuracy: 0.4303\n",
            "Epoch 287/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3536 - accuracy: 0.8402 - val_loss: 3.9824 - val_accuracy: 0.4384\n",
            "Epoch 288/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3495 - accuracy: 0.8402 - val_loss: 4.0387 - val_accuracy: 0.4374\n",
            "Epoch 289/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3501 - accuracy: 0.8414 - val_loss: 3.4903 - val_accuracy: 0.4224\n",
            "Epoch 290/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3492 - accuracy: 0.8425 - val_loss: 3.9045 - val_accuracy: 0.4261\n",
            "Epoch 291/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3480 - accuracy: 0.8421 - val_loss: 3.7849 - val_accuracy: 0.4242\n",
            "Epoch 292/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3493 - accuracy: 0.8431 - val_loss: 3.4092 - val_accuracy: 0.4238\n",
            "Epoch 293/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3481 - accuracy: 0.8433 - val_loss: 3.7120 - val_accuracy: 0.4227\n",
            "Epoch 294/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3452 - accuracy: 0.8434 - val_loss: 3.8593 - val_accuracy: 0.4251\n",
            "Epoch 295/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3447 - accuracy: 0.8451 - val_loss: 3.4243 - val_accuracy: 0.4266\n",
            "Epoch 296/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3454 - accuracy: 0.8452 - val_loss: 3.9008 - val_accuracy: 0.4253\n",
            "Epoch 297/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3448 - accuracy: 0.8444 - val_loss: 3.9263 - val_accuracy: 0.4205\n",
            "Epoch 298/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3370 - accuracy: 0.8490 - val_loss: 3.7607 - val_accuracy: 0.4154\n",
            "Epoch 299/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3458 - accuracy: 0.8458 - val_loss: 3.6442 - val_accuracy: 0.4123\n",
            "Epoch 300/400\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 0.3397 - accuracy: 0.8478 - val_loss: 4.1013 - val_accuracy: 0.4279\n",
            "Epoch 301/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3389 - accuracy: 0.8486 - val_loss: 3.6169 - val_accuracy: 0.4066\n",
            "Epoch 302/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3376 - accuracy: 0.8484 - val_loss: 3.9379 - val_accuracy: 0.4188\n",
            "Epoch 303/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3386 - accuracy: 0.8480 - val_loss: 3.7294 - val_accuracy: 0.4167\n",
            "Epoch 304/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.3375 - accuracy: 0.8485 - val_loss: 3.5925 - val_accuracy: 0.4113\n",
            "Epoch 305/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3344 - accuracy: 0.8507 - val_loss: 3.8505 - val_accuracy: 0.4283\n",
            "Epoch 306/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3360 - accuracy: 0.8478 - val_loss: 3.8720 - val_accuracy: 0.4274\n",
            "Epoch 307/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3318 - accuracy: 0.8519 - val_loss: 3.9723 - val_accuracy: 0.4256\n",
            "Epoch 308/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3367 - accuracy: 0.8486 - val_loss: 3.6510 - val_accuracy: 0.4329\n",
            "Epoch 309/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3375 - accuracy: 0.8477 - val_loss: 3.8152 - val_accuracy: 0.4246\n",
            "Epoch 310/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.3329 - accuracy: 0.8512 - val_loss: 3.8031 - val_accuracy: 0.4355\n",
            "Epoch 311/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3305 - accuracy: 0.8513 - val_loss: 3.8146 - val_accuracy: 0.4193\n",
            "Epoch 312/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3303 - accuracy: 0.8523 - val_loss: 3.7099 - val_accuracy: 0.4177\n",
            "Epoch 313/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3301 - accuracy: 0.8530 - val_loss: 3.5987 - val_accuracy: 0.4169\n",
            "Epoch 314/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3269 - accuracy: 0.8548 - val_loss: 3.5495 - val_accuracy: 0.4245\n",
            "Epoch 315/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3317 - accuracy: 0.8535 - val_loss: 3.8012 - val_accuracy: 0.4196\n",
            "Epoch 316/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3255 - accuracy: 0.8557 - val_loss: 3.8885 - val_accuracy: 0.4155\n",
            "Epoch 317/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3263 - accuracy: 0.8547 - val_loss: 3.8723 - val_accuracy: 0.4245\n",
            "Epoch 318/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3239 - accuracy: 0.8542 - val_loss: 3.9105 - val_accuracy: 0.4152\n",
            "Epoch 319/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3230 - accuracy: 0.8541 - val_loss: 4.1028 - val_accuracy: 0.4158\n",
            "Epoch 320/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3234 - accuracy: 0.8550 - val_loss: 3.8171 - val_accuracy: 0.4172\n",
            "Epoch 321/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3242 - accuracy: 0.8568 - val_loss: 3.8466 - val_accuracy: 0.4209\n",
            "Epoch 322/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3208 - accuracy: 0.8570 - val_loss: 4.1237 - val_accuracy: 0.4203\n",
            "Epoch 323/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3207 - accuracy: 0.8569 - val_loss: 3.8929 - val_accuracy: 0.4251\n",
            "Epoch 324/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3257 - accuracy: 0.8574 - val_loss: 3.8766 - val_accuracy: 0.4269\n",
            "Epoch 325/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3183 - accuracy: 0.8588 - val_loss: 3.9060 - val_accuracy: 0.4295\n",
            "Epoch 326/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3180 - accuracy: 0.8578 - val_loss: 4.1676 - val_accuracy: 0.4181\n",
            "Epoch 327/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3168 - accuracy: 0.8597 - val_loss: 4.3802 - val_accuracy: 0.4314\n",
            "Epoch 328/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3196 - accuracy: 0.8590 - val_loss: 3.8878 - val_accuracy: 0.4244\n",
            "Epoch 329/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3172 - accuracy: 0.8585 - val_loss: 3.9281 - val_accuracy: 0.4245\n",
            "Epoch 330/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3175 - accuracy: 0.8576 - val_loss: 4.0681 - val_accuracy: 0.4270\n",
            "Epoch 331/400\n",
            "272/272 [==============================] - 5s 18ms/step - loss: 0.3142 - accuracy: 0.8610 - val_loss: 3.8624 - val_accuracy: 0.4177\n",
            "Epoch 332/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3168 - accuracy: 0.8596 - val_loss: 4.0771 - val_accuracy: 0.4323\n",
            "Epoch 333/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.3144 - accuracy: 0.8610 - val_loss: 4.2002 - val_accuracy: 0.4192\n",
            "Epoch 334/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3186 - accuracy: 0.8598 - val_loss: 3.7451 - val_accuracy: 0.4196\n",
            "Epoch 335/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3164 - accuracy: 0.8609 - val_loss: 4.1547 - val_accuracy: 0.4192\n",
            "Epoch 336/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3103 - accuracy: 0.8631 - val_loss: 3.8385 - val_accuracy: 0.4218\n",
            "Epoch 337/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3108 - accuracy: 0.8616 - val_loss: 4.0671 - val_accuracy: 0.4274\n",
            "Epoch 338/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3090 - accuracy: 0.8640 - val_loss: 4.1428 - val_accuracy: 0.4278\n",
            "Epoch 339/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3092 - accuracy: 0.8623 - val_loss: 4.3519 - val_accuracy: 0.4357\n",
            "Epoch 340/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3081 - accuracy: 0.8639 - val_loss: 4.1632 - val_accuracy: 0.4169\n",
            "Epoch 341/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3106 - accuracy: 0.8629 - val_loss: 4.4457 - val_accuracy: 0.4259\n",
            "Epoch 342/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3055 - accuracy: 0.8641 - val_loss: 4.0542 - val_accuracy: 0.4182\n",
            "Epoch 343/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3097 - accuracy: 0.8634 - val_loss: 4.2439 - val_accuracy: 0.4245\n",
            "Epoch 344/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.3092 - accuracy: 0.8638 - val_loss: 4.2420 - val_accuracy: 0.4161\n",
            "Epoch 345/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3088 - accuracy: 0.8647 - val_loss: 4.3752 - val_accuracy: 0.4089\n",
            "Epoch 346/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3065 - accuracy: 0.8654 - val_loss: 4.4737 - val_accuracy: 0.4262\n",
            "Epoch 347/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3077 - accuracy: 0.8657 - val_loss: 4.1274 - val_accuracy: 0.4284\n",
            "Epoch 348/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3008 - accuracy: 0.8680 - val_loss: 4.5933 - val_accuracy: 0.4296\n",
            "Epoch 349/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3061 - accuracy: 0.8645 - val_loss: 4.0937 - val_accuracy: 0.4184\n",
            "Epoch 350/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3038 - accuracy: 0.8677 - val_loss: 4.0283 - val_accuracy: 0.4049\n",
            "Epoch 351/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3021 - accuracy: 0.8678 - val_loss: 4.4835 - val_accuracy: 0.4126\n",
            "Epoch 352/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3045 - accuracy: 0.8670 - val_loss: 4.2773 - val_accuracy: 0.4275\n",
            "Epoch 353/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2973 - accuracy: 0.8709 - val_loss: 4.2077 - val_accuracy: 0.4303\n",
            "Epoch 354/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2960 - accuracy: 0.8709 - val_loss: 3.9074 - val_accuracy: 0.4321\n",
            "Epoch 355/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3022 - accuracy: 0.8691 - val_loss: 3.9280 - val_accuracy: 0.4258\n",
            "Epoch 356/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3016 - accuracy: 0.8688 - val_loss: 4.9776 - val_accuracy: 0.4275\n",
            "Epoch 357/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2967 - accuracy: 0.8706 - val_loss: 3.9752 - val_accuracy: 0.4280\n",
            "Epoch 358/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2956 - accuracy: 0.8719 - val_loss: 4.4016 - val_accuracy: 0.4108\n",
            "Epoch 359/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2994 - accuracy: 0.8705 - val_loss: 4.0038 - val_accuracy: 0.4247\n",
            "Epoch 360/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2955 - accuracy: 0.8701 - val_loss: 3.7900 - val_accuracy: 0.4169\n",
            "Epoch 361/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2949 - accuracy: 0.8716 - val_loss: 4.3909 - val_accuracy: 0.4284\n",
            "Epoch 362/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2952 - accuracy: 0.8727 - val_loss: 4.4097 - val_accuracy: 0.4322\n",
            "Epoch 363/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2944 - accuracy: 0.8716 - val_loss: 4.0752 - val_accuracy: 0.4233\n",
            "Epoch 364/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.2939 - accuracy: 0.8705 - val_loss: 4.4540 - val_accuracy: 0.4162\n",
            "Epoch 365/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2924 - accuracy: 0.8737 - val_loss: 3.8814 - val_accuracy: 0.4227\n",
            "Epoch 366/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2902 - accuracy: 0.8733 - val_loss: 4.1032 - val_accuracy: 0.4173\n",
            "Epoch 367/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2914 - accuracy: 0.8734 - val_loss: 4.4496 - val_accuracy: 0.4253\n",
            "Epoch 368/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2862 - accuracy: 0.8760 - val_loss: 4.1254 - val_accuracy: 0.4248\n",
            "Epoch 369/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2876 - accuracy: 0.8753 - val_loss: 4.2328 - val_accuracy: 0.4251\n",
            "Epoch 370/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2888 - accuracy: 0.8755 - val_loss: 4.2244 - val_accuracy: 0.4301\n",
            "Epoch 371/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2885 - accuracy: 0.8763 - val_loss: 4.4364 - val_accuracy: 0.4244\n",
            "Epoch 372/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2858 - accuracy: 0.8763 - val_loss: 4.5980 - val_accuracy: 0.4226\n",
            "Epoch 373/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2873 - accuracy: 0.8749 - val_loss: 4.1878 - val_accuracy: 0.4221\n",
            "Epoch 374/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2878 - accuracy: 0.8755 - val_loss: 4.0979 - val_accuracy: 0.4175\n",
            "Epoch 375/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2840 - accuracy: 0.8766 - val_loss: 4.3435 - val_accuracy: 0.4162\n",
            "Epoch 376/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2862 - accuracy: 0.8782 - val_loss: 3.8259 - val_accuracy: 0.4102\n",
            "Epoch 377/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2871 - accuracy: 0.8769 - val_loss: 4.4452 - val_accuracy: 0.4215\n",
            "Epoch 378/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2855 - accuracy: 0.8761 - val_loss: 4.3372 - val_accuracy: 0.4294\n",
            "Epoch 379/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2832 - accuracy: 0.8773 - val_loss: 4.2484 - val_accuracy: 0.4175\n",
            "Epoch 380/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2892 - accuracy: 0.8756 - val_loss: 4.2567 - val_accuracy: 0.4155\n",
            "Epoch 381/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2850 - accuracy: 0.8788 - val_loss: 4.4796 - val_accuracy: 0.4289\n",
            "Epoch 382/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2788 - accuracy: 0.8799 - val_loss: 3.9167 - val_accuracy: 0.4247\n",
            "Epoch 383/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2794 - accuracy: 0.8795 - val_loss: 4.3552 - val_accuracy: 0.4146\n",
            "Epoch 384/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2798 - accuracy: 0.8794 - val_loss: 4.8760 - val_accuracy: 0.4288\n",
            "Epoch 385/400\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.2810 - accuracy: 0.8797 - val_loss: 4.1532 - val_accuracy: 0.4210\n",
            "Epoch 386/400\n",
            "272/272 [==============================] - 5s 17ms/step - loss: 0.2772 - accuracy: 0.8815 - val_loss: 4.7236 - val_accuracy: 0.4287\n",
            "Epoch 387/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2793 - accuracy: 0.8803 - val_loss: 4.1511 - val_accuracy: 0.4225\n",
            "Epoch 388/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2798 - accuracy: 0.8813 - val_loss: 4.4439 - val_accuracy: 0.4140\n",
            "Epoch 389/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2758 - accuracy: 0.8809 - val_loss: 4.5290 - val_accuracy: 0.4196\n",
            "Epoch 390/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2790 - accuracy: 0.8806 - val_loss: 4.6510 - val_accuracy: 0.4148\n",
            "Epoch 391/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2718 - accuracy: 0.8828 - val_loss: 4.4363 - val_accuracy: 0.4186\n",
            "Epoch 392/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2721 - accuracy: 0.8830 - val_loss: 4.8303 - val_accuracy: 0.4281\n",
            "Epoch 393/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2748 - accuracy: 0.8815 - val_loss: 4.3994 - val_accuracy: 0.4230\n",
            "Epoch 394/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2716 - accuracy: 0.8830 - val_loss: 4.9329 - val_accuracy: 0.4177\n",
            "Epoch 395/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2739 - accuracy: 0.8823 - val_loss: 4.4921 - val_accuracy: 0.4279\n",
            "Epoch 396/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2742 - accuracy: 0.8826 - val_loss: 4.3317 - val_accuracy: 0.4338\n",
            "Epoch 397/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.2748 - accuracy: 0.8836 - val_loss: 4.7927 - val_accuracy: 0.4304\n",
            "Epoch 398/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.2751 - accuracy: 0.8836 - val_loss: 4.2221 - val_accuracy: 0.4333\n",
            "Epoch 399/400\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2703 - accuracy: 0.8840 - val_loss: 4.3020 - val_accuracy: 0.4167\n",
            "Epoch 400/400\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.2692 - accuracy: 0.8862 - val_loss: 3.9404 - val_accuracy: 0.4205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss: 0.4268 - accuracy: 0.8180 - val_loss: 8.4523 - val_accuracy: 0.4353"
      ],
      "metadata": {
        "id": "0iLYhrho-vNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The argument being passed to each Dense layer (16) is the number of hidden\n",
        "units of the layer. A hidden unit is a dimension in the representation space of the layer.\n",
        "You may remember from chapter 2 that each such Dense layer with a relu activation\n",
        "implements the following chain of tensor operations:\n",
        "output = relu(dot(W, input) + b)\n",
        "Having 16 hidden units means the weight matrix W will have shape (input_dimension,\n",
        "16): the dot product with W will project the input data onto a 16-dimensional representation space (and then you’ll add the bias vector b and apply the relu operation)."
      ],
      "metadata": {
        "id": "V8-VTui9r5BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./models/model_db_20_layer_09_22_2022.h5')"
      ],
      "metadata": {
        "id": "FG38n5X6h29p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Detail**\n",
        "model.add(layers.Dense(4096, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "**Lưu tại /models/model_db_09_22_2022.h5**\n",
        "\n",
        "**loss: 0.1897 - accuracy: 0.9276**\n",
        "\n",
        "**Model Summary:**\n",
        "\n",
        "dense_9 (Dense)             (None, 4096)              53248     \n",
        "                                                                 \n",
        "dense_10 (Dense)            (None, 4096)              16781312  \n",
        "                                                                 \n",
        "dense_11 (Dense)            (None, 3)                 12291 \n",
        "\n",
        "**Model Detail** 10 layers\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "**Lưu tại /models/model_db_10_layer_09_22_2022.h5**\n",
        "\n",
        "**loss: 0.1173 - accuracy: 0.9577**\n",
        "\n",
        "**Model Summary:**\n",
        "\n",
        "Model: \"sequential_7\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " dense_31 (Dense)            (None, 32)                416       \n",
        "                                                                 \n",
        " dense_32 (Dense)            (None, 64)                2112      \n",
        "                                                                 \n",
        " dense_33 (Dense)            (None, 128)               8320      \n",
        "                                                                 \n",
        " dense_34 (Dense)            (None, 256)               33024     \n",
        "                                                                 \n",
        " dense_35 (Dense)            (None, 256)               65792     \n",
        "                                                                 \n",
        " dense_36 (Dense)            (None, 128)               32896     \n",
        "                                                                 \n",
        " dense_37 (Dense)            (None, 64)                8256      \n",
        "                                                                 \n",
        " dense_38 (Dense)            (None, 32)                2080      \n",
        "                                                                 \n",
        " dense_39 (Dense)            (None, 16)                528       \n",
        "                                                                 \n",
        " dense_40 (Dense)            (None, 3)                 51  \n"
      ],
      "metadata": {
        "id": "RjrS6Ppan11b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training loss and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IDi6e4n6108l",
        "outputId": "328e5e82-2d3a-4af4-bbdc-342407bc0aa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}